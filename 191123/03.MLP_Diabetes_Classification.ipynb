{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2019.11.23. 딥-러닝 과정 Mulit Layer Perceptron(MLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 세번째 실습. Keras 모델 생성/학습 - 당뇨병 예측 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py35/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/anaconda/envs/py35/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# 1. Pandas 가져오기\n",
    "import pandas as pd\n",
    "\n",
    "print(pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pregnant</th>\n",
       "      <th>gloucose</th>\n",
       "      <th>blood pressure</th>\n",
       "      <th>skin thickness</th>\n",
       "      <th>insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DPF</th>\n",
       "      <th>age</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>116</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.6</td>\n",
       "      <td>0.201</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>78</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>88</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.248</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>115</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.3</td>\n",
       "      <td>0.134</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>197</td>\n",
       "      <td>70</td>\n",
       "      <td>45</td>\n",
       "      <td>543</td>\n",
       "      <td>30.5</td>\n",
       "      <td>0.158</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>125</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.232</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pregnant  gloucose  blood pressure  skin thickness  insulin   BMI    DPF  \\\n",
       "0         6       148              72              35        0  33.6  0.627   \n",
       "1         1        85              66              29        0  26.6  0.351   \n",
       "2         8       183              64               0        0  23.3  0.672   \n",
       "3         1        89              66              23       94  28.1  0.167   \n",
       "4         0       137              40              35      168  43.1  2.288   \n",
       "5         5       116              74               0        0  25.6  0.201   \n",
       "6         3        78              50              32       88  31.0  0.248   \n",
       "7        10       115               0               0        0  35.3  0.134   \n",
       "8         2       197              70              45      543  30.5  0.158   \n",
       "9         8       125              96               0        0   0.0  0.232   \n",
       "\n",
       "   age  result  \n",
       "0   50       1  \n",
       "1   31       0  \n",
       "2   32       1  \n",
       "3   21       0  \n",
       "4   33       1  \n",
       "5   30       0  \n",
       "6   26       1  \n",
       "7   29       0  \n",
       "8   53       1  \n",
       "9   54       1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. 데이터 불러오기\n",
    "dataset = pd.read_csv('diabetes_data.csv')\n",
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 8)\n",
      "(768,)\n"
     ]
    }
   ],
   "source": [
    "# 3. X/y 나누기\n",
    "\n",
    "X = dataset.iloc[:, :-1]\n",
    "y = dataset.iloc[:, -1]\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(537, 8)\n",
      "(537,)\n",
      "(115, 8)\n",
      "(115,)\n",
      "(116, 8)\n",
      "(116,)\n"
     ]
    }
   ],
   "source": [
    "# 4. Train set, Test set 나누기\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=9)\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test,\n",
    "                                               test_size=0.5,\n",
    "                                               random_state=123)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)\n",
    "\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.4\n"
     ]
    }
   ],
   "source": [
    "# 5. Keras 패키지 가져오기\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "import keras\n",
    "\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda/envs/py35/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 12)                108       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 8)                 104       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 221\n",
      "Trainable params: 221\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# 6. MLP 모델 생성\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, \n",
    "                activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Compile - Optimizer, Loss function 설정\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 537 samples, validate on 115 samples\n",
      "Epoch 1/1000\n",
      "537/537 [==============================] - 1s 970us/step - loss: 4.9289 - acc: 0.5736 - val_loss: 3.2560 - val_acc: 0.6609\n",
      "Epoch 2/1000\n",
      "537/537 [==============================] - 0s 88us/step - loss: 3.4709 - acc: 0.6425 - val_loss: 3.2140 - val_acc: 0.6522\n",
      "Epoch 3/1000\n",
      "537/537 [==============================] - 0s 81us/step - loss: 3.7243 - acc: 0.5940 - val_loss: 3.0675 - val_acc: 0.6696\n",
      "Epoch 4/1000\n",
      "537/537 [==============================] - 0s 85us/step - loss: 3.1871 - acc: 0.5940 - val_loss: 3.0582 - val_acc: 0.6522\n",
      "Epoch 5/1000\n",
      "537/537 [==============================] - 0s 88us/step - loss: 2.8122 - acc: 0.6369 - val_loss: 2.8971 - val_acc: 0.6522\n",
      "Epoch 6/1000\n",
      "537/537 [==============================] - 0s 79us/step - loss: 2.5671 - acc: 0.6294 - val_loss: 2.6111 - val_acc: 0.6435\n",
      "Epoch 7/1000\n",
      "537/537 [==============================] - 0s 83us/step - loss: 2.3731 - acc: 0.5996 - val_loss: 2.0626 - val_acc: 0.6696\n",
      "Epoch 8/1000\n",
      "537/537 [==============================] - 0s 83us/step - loss: 1.7937 - acc: 0.5847 - val_loss: 1.5834 - val_acc: 0.6609\n",
      "Epoch 9/1000\n",
      "537/537 [==============================] - 0s 81us/step - loss: 1.6339 - acc: 0.6182 - val_loss: 1.2024 - val_acc: 0.6174\n",
      "Epoch 10/1000\n",
      "537/537 [==============================] - 0s 81us/step - loss: 1.5946 - acc: 0.5940 - val_loss: 0.9405 - val_acc: 0.5826\n",
      "Epoch 11/1000\n",
      "537/537 [==============================] - 0s 82us/step - loss: 1.3022 - acc: 0.6201 - val_loss: 0.7955 - val_acc: 0.6348\n",
      "Epoch 12/1000\n",
      "537/537 [==============================] - 0s 86us/step - loss: 1.0395 - acc: 0.6257 - val_loss: 0.7606 - val_acc: 0.6522\n",
      "Epoch 13/1000\n",
      "537/537 [==============================] - 0s 85us/step - loss: 1.0333 - acc: 0.6313 - val_loss: 0.6916 - val_acc: 0.6609\n",
      "Epoch 14/1000\n",
      "537/537 [==============================] - 0s 81us/step - loss: 1.0811 - acc: 0.6387 - val_loss: 0.6544 - val_acc: 0.6696\n",
      "Epoch 15/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.9503 - acc: 0.6238 - val_loss: 0.6410 - val_acc: 0.6696\n",
      "Epoch 16/1000\n",
      "537/537 [==============================] - 0s 83us/step - loss: 0.9102 - acc: 0.6238 - val_loss: 0.6372 - val_acc: 0.6609\n",
      "Epoch 17/1000\n",
      "537/537 [==============================] - 0s 83us/step - loss: 0.8344 - acc: 0.6480 - val_loss: 0.6374 - val_acc: 0.6696\n",
      "Epoch 18/1000\n",
      "537/537 [==============================] - 0s 82us/step - loss: 0.7724 - acc: 0.6313 - val_loss: 0.6348 - val_acc: 0.6609\n",
      "Epoch 19/1000\n",
      "537/537 [==============================] - 0s 80us/step - loss: 0.8304 - acc: 0.6518 - val_loss: 0.6359 - val_acc: 0.6609\n",
      "Epoch 20/1000\n",
      "537/537 [==============================] - 0s 77us/step - loss: 0.7775 - acc: 0.6499 - val_loss: 0.6357 - val_acc: 0.6609\n",
      "Epoch 21/1000\n",
      "537/537 [==============================] - 0s 123us/step - loss: 0.7476 - acc: 0.6387 - val_loss: 0.6358 - val_acc: 0.6522\n",
      "Epoch 22/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.7491 - acc: 0.6331 - val_loss: 0.6352 - val_acc: 0.6696\n",
      "Epoch 23/1000\n",
      "537/537 [==============================] - 0s 80us/step - loss: 0.7346 - acc: 0.6592 - val_loss: 0.6361 - val_acc: 0.6609\n",
      "Epoch 24/1000\n",
      "537/537 [==============================] - 0s 80us/step - loss: 0.7006 - acc: 0.6574 - val_loss: 0.6366 - val_acc: 0.6609\n",
      "Epoch 25/1000\n",
      "537/537 [==============================] - 0s 85us/step - loss: 0.6731 - acc: 0.6667 - val_loss: 0.6352 - val_acc: 0.6696\n",
      "Epoch 26/1000\n",
      "537/537 [==============================] - 0s 82us/step - loss: 0.6758 - acc: 0.6555 - val_loss: 0.6349 - val_acc: 0.6696\n",
      "Epoch 27/1000\n",
      "537/537 [==============================] - 0s 87us/step - loss: 0.7270 - acc: 0.6425 - val_loss: 0.6346 - val_acc: 0.6696\n",
      "Epoch 28/1000\n",
      "537/537 [==============================] - 0s 82us/step - loss: 0.6777 - acc: 0.6331 - val_loss: 0.6337 - val_acc: 0.6696\n",
      "Epoch 29/1000\n",
      "537/537 [==============================] - 0s 89us/step - loss: 0.6606 - acc: 0.6629 - val_loss: 0.6324 - val_acc: 0.6696\n",
      "Epoch 30/1000\n",
      "537/537 [==============================] - 0s 89us/step - loss: 0.6660 - acc: 0.6741 - val_loss: 0.6309 - val_acc: 0.6696\n",
      "Epoch 31/1000\n",
      "537/537 [==============================] - 0s 75us/step - loss: 0.6676 - acc: 0.6574 - val_loss: 0.6310 - val_acc: 0.6696\n",
      "Epoch 32/1000\n",
      "537/537 [==============================] - 0s 77us/step - loss: 0.6551 - acc: 0.6629 - val_loss: 0.6315 - val_acc: 0.6696\n",
      "Epoch 33/1000\n",
      "537/537 [==============================] - 0s 84us/step - loss: 0.6554 - acc: 0.6518 - val_loss: 0.6311 - val_acc: 0.6696\n",
      "Epoch 34/1000\n",
      "537/537 [==============================] - 0s 75us/step - loss: 0.6498 - acc: 0.6536 - val_loss: 0.6295 - val_acc: 0.6696\n",
      "Epoch 35/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.6790 - acc: 0.6611 - val_loss: 0.6266 - val_acc: 0.6696\n",
      "Epoch 36/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.6623 - acc: 0.6592 - val_loss: 0.6273 - val_acc: 0.6696\n",
      "Epoch 37/1000\n",
      "537/537 [==============================] - 0s 71us/step - loss: 0.6741 - acc: 0.6611 - val_loss: 0.6251 - val_acc: 0.6696\n",
      "Epoch 38/1000\n",
      "537/537 [==============================] - 0s 75us/step - loss: 0.6446 - acc: 0.6536 - val_loss: 0.6230 - val_acc: 0.6696\n",
      "Epoch 39/1000\n",
      "537/537 [==============================] - 0s 83us/step - loss: 0.6526 - acc: 0.6629 - val_loss: 0.6233 - val_acc: 0.6696\n",
      "Epoch 40/1000\n",
      "537/537 [==============================] - 0s 76us/step - loss: 0.6268 - acc: 0.6704 - val_loss: 0.6194 - val_acc: 0.6696\n",
      "Epoch 41/1000\n",
      "537/537 [==============================] - 0s 76us/step - loss: 0.6486 - acc: 0.6685 - val_loss: 0.6191 - val_acc: 0.6696\n",
      "Epoch 42/1000\n",
      "537/537 [==============================] - 0s 76us/step - loss: 0.6436 - acc: 0.6685 - val_loss: 0.6196 - val_acc: 0.6696\n",
      "Epoch 43/1000\n",
      "537/537 [==============================] - 0s 75us/step - loss: 0.6505 - acc: 0.6555 - val_loss: 0.6185 - val_acc: 0.6696\n",
      "Epoch 44/1000\n",
      "537/537 [==============================] - 0s 81us/step - loss: 0.6573 - acc: 0.6574 - val_loss: 0.6190 - val_acc: 0.6696\n",
      "Epoch 45/1000\n",
      "537/537 [==============================] - 0s 80us/step - loss: 0.6461 - acc: 0.6555 - val_loss: 0.6174 - val_acc: 0.6696\n",
      "Epoch 46/1000\n",
      "537/537 [==============================] - 0s 81us/step - loss: 0.6333 - acc: 0.6778 - val_loss: 0.6169 - val_acc: 0.6870\n",
      "Epoch 47/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.6260 - acc: 0.6723 - val_loss: 0.6171 - val_acc: 0.6870\n",
      "Epoch 48/1000\n",
      "537/537 [==============================] - 0s 79us/step - loss: 0.6325 - acc: 0.6853 - val_loss: 0.6134 - val_acc: 0.6870\n",
      "Epoch 49/1000\n",
      "537/537 [==============================] - 0s 81us/step - loss: 0.6302 - acc: 0.6723 - val_loss: 0.6144 - val_acc: 0.6870\n",
      "Epoch 50/1000\n",
      "537/537 [==============================] - 0s 81us/step - loss: 0.6471 - acc: 0.6499 - val_loss: 0.6149 - val_acc: 0.6783\n",
      "Epoch 51/1000\n",
      "537/537 [==============================] - 0s 82us/step - loss: 0.6447 - acc: 0.6611 - val_loss: 0.6168 - val_acc: 0.6696\n",
      "Epoch 52/1000\n",
      "537/537 [==============================] - 0s 93us/step - loss: 0.6509 - acc: 0.6574 - val_loss: 0.6177 - val_acc: 0.6696\n",
      "Epoch 53/1000\n",
      "537/537 [==============================] - 0s 82us/step - loss: 0.6340 - acc: 0.6685 - val_loss: 0.6135 - val_acc: 0.6696\n",
      "Epoch 54/1000\n",
      "537/537 [==============================] - 0s 79us/step - loss: 0.6284 - acc: 0.6741 - val_loss: 0.6125 - val_acc: 0.6696\n",
      "Epoch 55/1000\n",
      "537/537 [==============================] - 0s 83us/step - loss: 0.6444 - acc: 0.6723 - val_loss: 0.6112 - val_acc: 0.6783\n",
      "Epoch 56/1000\n",
      "537/537 [==============================] - 0s 81us/step - loss: 0.6458 - acc: 0.6648 - val_loss: 0.6122 - val_acc: 0.6783\n",
      "Epoch 57/1000\n",
      "537/537 [==============================] - 0s 88us/step - loss: 0.6474 - acc: 0.6629 - val_loss: 0.6136 - val_acc: 0.6783\n",
      "Epoch 58/1000\n",
      "537/537 [==============================] - 0s 85us/step - loss: 0.6373 - acc: 0.6667 - val_loss: 0.6148 - val_acc: 0.6783\n",
      "Epoch 59/1000\n",
      "537/537 [==============================] - 0s 88us/step - loss: 0.6417 - acc: 0.6592 - val_loss: 0.6151 - val_acc: 0.6696\n",
      "Epoch 60/1000\n",
      "537/537 [==============================] - 0s 75us/step - loss: 0.6252 - acc: 0.6797 - val_loss: 0.6139 - val_acc: 0.6783\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/1000\n",
      "537/537 [==============================] - 0s 79us/step - loss: 0.6357 - acc: 0.6536 - val_loss: 0.6146 - val_acc: 0.6696\n",
      "Epoch 62/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.6384 - acc: 0.6518 - val_loss: 0.6166 - val_acc: 0.6696\n",
      "Epoch 63/1000\n",
      "537/537 [==============================] - 0s 75us/step - loss: 0.6397 - acc: 0.6648 - val_loss: 0.6158 - val_acc: 0.6696\n",
      "Epoch 64/1000\n",
      "537/537 [==============================] - 0s 83us/step - loss: 0.6249 - acc: 0.6760 - val_loss: 0.6135 - val_acc: 0.6783\n",
      "Epoch 65/1000\n",
      "537/537 [==============================] - 0s 87us/step - loss: 0.6467 - acc: 0.6611 - val_loss: 0.6123 - val_acc: 0.6783\n",
      "Epoch 66/1000\n",
      "537/537 [==============================] - 0s 91us/step - loss: 0.6285 - acc: 0.6704 - val_loss: 0.6126 - val_acc: 0.6783\n",
      "Epoch 67/1000\n",
      "537/537 [==============================] - 0s 94us/step - loss: 0.6318 - acc: 0.6741 - val_loss: 0.6126 - val_acc: 0.6783\n",
      "Epoch 68/1000\n",
      "537/537 [==============================] - 0s 85us/step - loss: 0.6242 - acc: 0.6704 - val_loss: 0.6114 - val_acc: 0.6783\n",
      "Epoch 69/1000\n",
      "537/537 [==============================] - 0s 90us/step - loss: 0.6475 - acc: 0.6592 - val_loss: 0.6119 - val_acc: 0.6783\n",
      "Epoch 70/1000\n",
      "537/537 [==============================] - 0s 79us/step - loss: 0.6361 - acc: 0.6592 - val_loss: 0.6145 - val_acc: 0.6696\n",
      "Epoch 71/1000\n",
      "537/537 [==============================] - 0s 77us/step - loss: 0.6375 - acc: 0.6629 - val_loss: 0.6152 - val_acc: 0.6696\n",
      "Epoch 72/1000\n",
      "537/537 [==============================] - 0s 77us/step - loss: 0.6454 - acc: 0.6648 - val_loss: 0.6160 - val_acc: 0.6696\n",
      "Epoch 73/1000\n",
      "537/537 [==============================] - 0s 80us/step - loss: 0.6359 - acc: 0.6555 - val_loss: 0.6177 - val_acc: 0.6696\n",
      "Epoch 74/1000\n",
      "537/537 [==============================] - 0s 73us/step - loss: 0.6301 - acc: 0.6648 - val_loss: 0.6155 - val_acc: 0.6696\n",
      "Epoch 75/1000\n",
      "537/537 [==============================] - 0s 76us/step - loss: 0.6349 - acc: 0.6685 - val_loss: 0.6160 - val_acc: 0.6696\n",
      "Epoch 76/1000\n",
      "537/537 [==============================] - 0s 76us/step - loss: 0.6264 - acc: 0.6741 - val_loss: 0.6144 - val_acc: 0.6696\n",
      "Epoch 77/1000\n",
      "537/537 [==============================] - 0s 73us/step - loss: 0.6304 - acc: 0.6667 - val_loss: 0.6106 - val_acc: 0.6783\n",
      "Epoch 78/1000\n",
      "537/537 [==============================] - 0s 77us/step - loss: 0.6430 - acc: 0.6611 - val_loss: 0.6104 - val_acc: 0.6783\n",
      "Epoch 79/1000\n",
      "537/537 [==============================] - 0s 79us/step - loss: 0.6339 - acc: 0.6629 - val_loss: 0.6099 - val_acc: 0.6783\n",
      "Epoch 80/1000\n",
      "537/537 [==============================] - 0s 75us/step - loss: 0.6377 - acc: 0.6611 - val_loss: 0.6097 - val_acc: 0.6783\n",
      "Epoch 81/1000\n",
      "537/537 [==============================] - 0s 74us/step - loss: 0.6475 - acc: 0.6574 - val_loss: 0.6115 - val_acc: 0.6696\n",
      "Epoch 82/1000\n",
      "537/537 [==============================] - 0s 74us/step - loss: 0.6290 - acc: 0.6723 - val_loss: 0.6125 - val_acc: 0.6696\n",
      "Epoch 83/1000\n",
      "537/537 [==============================] - 0s 82us/step - loss: 0.6381 - acc: 0.6574 - val_loss: 0.6104 - val_acc: 0.6696\n",
      "Epoch 84/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.6347 - acc: 0.6518 - val_loss: 0.6132 - val_acc: 0.6783\n",
      "Epoch 85/1000\n",
      "537/537 [==============================] - 0s 82us/step - loss: 0.6383 - acc: 0.6629 - val_loss: 0.6145 - val_acc: 0.6783\n",
      "Epoch 86/1000\n",
      "537/537 [==============================] - 0s 75us/step - loss: 0.6362 - acc: 0.6741 - val_loss: 0.6115 - val_acc: 0.6783\n",
      "Epoch 87/1000\n",
      "537/537 [==============================] - 0s 72us/step - loss: 0.6311 - acc: 0.6648 - val_loss: 0.6133 - val_acc: 0.6696\n",
      "Epoch 88/1000\n",
      "537/537 [==============================] - 0s 76us/step - loss: 0.6338 - acc: 0.6648 - val_loss: 0.6148 - val_acc: 0.6696\n",
      "Epoch 89/1000\n",
      "537/537 [==============================] - 0s 74us/step - loss: 0.6338 - acc: 0.6704 - val_loss: 0.6129 - val_acc: 0.6696\n",
      "Epoch 90/1000\n",
      "537/537 [==============================] - 0s 76us/step - loss: 0.6297 - acc: 0.6760 - val_loss: 0.6080 - val_acc: 0.6783\n",
      "Epoch 91/1000\n",
      "537/537 [==============================] - 0s 75us/step - loss: 0.6398 - acc: 0.6648 - val_loss: 0.6080 - val_acc: 0.6783\n",
      "Epoch 92/1000\n",
      "537/537 [==============================] - 0s 74us/step - loss: 0.6221 - acc: 0.6704 - val_loss: 0.6096 - val_acc: 0.6783\n",
      "Epoch 93/1000\n",
      "537/537 [==============================] - 0s 76us/step - loss: 0.6254 - acc: 0.6704 - val_loss: 0.6083 - val_acc: 0.6870\n",
      "Epoch 94/1000\n",
      "537/537 [==============================] - 0s 75us/step - loss: 0.6403 - acc: 0.6648 - val_loss: 0.6103 - val_acc: 0.6783\n",
      "Epoch 95/1000\n",
      "537/537 [==============================] - 0s 102us/step - loss: 0.6318 - acc: 0.6760 - val_loss: 0.6082 - val_acc: 0.6783\n",
      "Epoch 96/1000\n",
      "537/537 [==============================] - 0s 81us/step - loss: 0.6320 - acc: 0.6592 - val_loss: 0.6109 - val_acc: 0.6783\n",
      "Epoch 97/1000\n",
      "537/537 [==============================] - 0s 80us/step - loss: 0.6245 - acc: 0.6760 - val_loss: 0.6072 - val_acc: 0.6783\n",
      "Epoch 98/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.6429 - acc: 0.6723 - val_loss: 0.6092 - val_acc: 0.6783\n",
      "Epoch 99/1000\n",
      "537/537 [==============================] - 0s 74us/step - loss: 0.6379 - acc: 0.6797 - val_loss: 0.6106 - val_acc: 0.6696\n",
      "Epoch 100/1000\n",
      "537/537 [==============================] - 0s 75us/step - loss: 0.6282 - acc: 0.6816 - val_loss: 0.6098 - val_acc: 0.6696\n",
      "Epoch 101/1000\n",
      "537/537 [==============================] - 0s 75us/step - loss: 0.6324 - acc: 0.6648 - val_loss: 0.6107 - val_acc: 0.6696\n",
      "Epoch 102/1000\n",
      "537/537 [==============================] - 0s 74us/step - loss: 0.6248 - acc: 0.6704 - val_loss: 0.6084 - val_acc: 0.6783\n",
      "Epoch 103/1000\n",
      "537/537 [==============================] - 0s 74us/step - loss: 0.6341 - acc: 0.6667 - val_loss: 0.6082 - val_acc: 0.6783\n",
      "Epoch 104/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.6241 - acc: 0.6741 - val_loss: 0.6092 - val_acc: 0.6783\n",
      "Epoch 105/1000\n",
      "537/537 [==============================] - 0s 89us/step - loss: 0.6334 - acc: 0.6704 - val_loss: 0.6064 - val_acc: 0.6870\n",
      "Epoch 106/1000\n",
      "537/537 [==============================] - 0s 73us/step - loss: 0.6241 - acc: 0.6778 - val_loss: 0.6068 - val_acc: 0.6870\n",
      "Epoch 107/1000\n",
      "537/537 [==============================] - 0s 79us/step - loss: 0.6317 - acc: 0.6704 - val_loss: 0.6071 - val_acc: 0.6783\n",
      "Epoch 108/1000\n",
      "537/537 [==============================] - 0s 80us/step - loss: 0.6324 - acc: 0.6704 - val_loss: 0.6072 - val_acc: 0.6783\n",
      "Epoch 109/1000\n",
      "537/537 [==============================] - 0s 87us/step - loss: 0.6310 - acc: 0.6778 - val_loss: 0.6069 - val_acc: 0.6783\n",
      "Epoch 110/1000\n",
      "537/537 [==============================] - 0s 83us/step - loss: 0.6221 - acc: 0.6834 - val_loss: 0.6032 - val_acc: 0.6783\n",
      "Epoch 111/1000\n",
      "537/537 [==============================] - 0s 81us/step - loss: 0.6276 - acc: 0.6685 - val_loss: 0.6059 - val_acc: 0.6783\n",
      "Epoch 112/1000\n",
      "537/537 [==============================] - 0s 84us/step - loss: 0.6373 - acc: 0.6760 - val_loss: 0.6073 - val_acc: 0.6783\n",
      "Epoch 113/1000\n",
      "537/537 [==============================] - 0s 80us/step - loss: 0.6225 - acc: 0.6723 - val_loss: 0.6046 - val_acc: 0.6783\n",
      "Epoch 114/1000\n",
      "537/537 [==============================] - 0s 82us/step - loss: 0.6169 - acc: 0.6760 - val_loss: 0.6003 - val_acc: 0.6783\n",
      "Epoch 115/1000\n",
      "537/537 [==============================] - 0s 83us/step - loss: 0.6250 - acc: 0.6816 - val_loss: 0.6024 - val_acc: 0.6783\n",
      "Epoch 116/1000\n",
      "537/537 [==============================] - 0s 94us/step - loss: 0.6285 - acc: 0.6704 - val_loss: 0.6039 - val_acc: 0.6783\n",
      "Epoch 117/1000\n",
      "537/537 [==============================] - 0s 83us/step - loss: 0.5974 - acc: 0.7058 - val_loss: 0.6028 - val_acc: 0.6783\n",
      "Epoch 118/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.6294 - acc: 0.6685 - val_loss: 0.6026 - val_acc: 0.6783\n",
      "Epoch 119/1000\n",
      "537/537 [==============================] - 0s 82us/step - loss: 0.6177 - acc: 0.6741 - val_loss: 0.6025 - val_acc: 0.6783\n",
      "Epoch 120/1000\n",
      "537/537 [==============================] - 0s 84us/step - loss: 0.6231 - acc: 0.6685 - val_loss: 0.6037 - val_acc: 0.6783\n",
      "Epoch 121/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "537/537 [==============================] - 0s 90us/step - loss: 0.6052 - acc: 0.6834 - val_loss: 0.6014 - val_acc: 0.6783\n",
      "Epoch 122/1000\n",
      "537/537 [==============================] - 0s 77us/step - loss: 0.6294 - acc: 0.6741 - val_loss: 0.6007 - val_acc: 0.6957\n",
      "Epoch 123/1000\n",
      "537/537 [==============================] - 0s 79us/step - loss: 0.6087 - acc: 0.6890 - val_loss: 0.5998 - val_acc: 0.6870\n",
      "Epoch 124/1000\n",
      "537/537 [==============================] - 0s 83us/step - loss: 0.6225 - acc: 0.6685 - val_loss: 0.5998 - val_acc: 0.6783\n",
      "Epoch 125/1000\n",
      "537/537 [==============================] - 0s 90us/step - loss: 0.6143 - acc: 0.6816 - val_loss: 0.5948 - val_acc: 0.6783\n",
      "Epoch 126/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.6093 - acc: 0.6778 - val_loss: 0.6010 - val_acc: 0.6870\n",
      "Epoch 127/1000\n",
      "537/537 [==============================] - 0s 85us/step - loss: 0.6179 - acc: 0.6723 - val_loss: 0.6005 - val_acc: 0.6783\n",
      "Epoch 128/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.6262 - acc: 0.6704 - val_loss: 0.6031 - val_acc: 0.6696\n",
      "Epoch 129/1000\n",
      "537/537 [==============================] - 0s 81us/step - loss: 0.6115 - acc: 0.6816 - val_loss: 0.6009 - val_acc: 0.6696\n",
      "Epoch 130/1000\n",
      "537/537 [==============================] - 0s 81us/step - loss: 0.6343 - acc: 0.6778 - val_loss: 0.6061 - val_acc: 0.6696\n",
      "Epoch 131/1000\n",
      "537/537 [==============================] - 0s 79us/step - loss: 0.6168 - acc: 0.6834 - val_loss: 0.5956 - val_acc: 0.6783\n",
      "Epoch 132/1000\n",
      "537/537 [==============================] - 0s 81us/step - loss: 0.6297 - acc: 0.6685 - val_loss: 0.5920 - val_acc: 0.6870\n",
      "Epoch 133/1000\n",
      "537/537 [==============================] - 0s 79us/step - loss: 0.6219 - acc: 0.6778 - val_loss: 0.5971 - val_acc: 0.6696\n",
      "Epoch 134/1000\n",
      "537/537 [==============================] - 0s 82us/step - loss: 0.6289 - acc: 0.6629 - val_loss: 0.5976 - val_acc: 0.6696\n",
      "Epoch 135/1000\n",
      "537/537 [==============================] - 0s 81us/step - loss: 0.6314 - acc: 0.6667 - val_loss: 0.5956 - val_acc: 0.6783\n",
      "Epoch 136/1000\n",
      "537/537 [==============================] - 0s 90us/step - loss: 0.6188 - acc: 0.6816 - val_loss: 0.5963 - val_acc: 0.6783\n",
      "Epoch 137/1000\n",
      "537/537 [==============================] - 0s 94us/step - loss: 0.6151 - acc: 0.6778 - val_loss: 0.5894 - val_acc: 0.6870\n",
      "Epoch 138/1000\n",
      "537/537 [==============================] - 0s 87us/step - loss: 0.6241 - acc: 0.6667 - val_loss: 0.5962 - val_acc: 0.6696\n",
      "Epoch 139/1000\n",
      "537/537 [==============================] - 0s 84us/step - loss: 0.6053 - acc: 0.6946 - val_loss: 0.5903 - val_acc: 0.6870\n",
      "Epoch 140/1000\n",
      "537/537 [==============================] - 0s 83us/step - loss: 0.6023 - acc: 0.6965 - val_loss: 0.5825 - val_acc: 0.6957\n",
      "Epoch 141/1000\n",
      "537/537 [==============================] - 0s 82us/step - loss: 0.6159 - acc: 0.6816 - val_loss: 0.5852 - val_acc: 0.6957\n",
      "Epoch 142/1000\n",
      "537/537 [==============================] - 0s 83us/step - loss: 0.6073 - acc: 0.6741 - val_loss: 0.5852 - val_acc: 0.6870\n",
      "Epoch 143/1000\n",
      "537/537 [==============================] - 0s 82us/step - loss: 0.6183 - acc: 0.6704 - val_loss: 0.5845 - val_acc: 0.6870\n",
      "Epoch 144/1000\n",
      "537/537 [==============================] - 0s 80us/step - loss: 0.6115 - acc: 0.6816 - val_loss: 0.5828 - val_acc: 0.6870\n",
      "Epoch 145/1000\n",
      "537/537 [==============================] - 0s 85us/step - loss: 0.6139 - acc: 0.6667 - val_loss: 0.5869 - val_acc: 0.6870\n",
      "Epoch 146/1000\n",
      "537/537 [==============================] - 0s 81us/step - loss: 0.6139 - acc: 0.6797 - val_loss: 0.5876 - val_acc: 0.6783\n",
      "Epoch 147/1000\n",
      "537/537 [==============================] - 0s 89us/step - loss: 0.6256 - acc: 0.6667 - val_loss: 0.5865 - val_acc: 0.6783\n",
      "Epoch 148/1000\n",
      "537/537 [==============================] - 0s 81us/step - loss: 0.6214 - acc: 0.6685 - val_loss: 0.5916 - val_acc: 0.6783\n",
      "Epoch 149/1000\n",
      "537/537 [==============================] - 0s 82us/step - loss: 0.6346 - acc: 0.6574 - val_loss: 0.5871 - val_acc: 0.6870\n",
      "Epoch 150/1000\n",
      "537/537 [==============================] - 0s 77us/step - loss: 0.6255 - acc: 0.6648 - val_loss: 0.5875 - val_acc: 0.6870\n",
      "Epoch 151/1000\n",
      "537/537 [==============================] - 0s 82us/step - loss: 0.6215 - acc: 0.6518 - val_loss: 0.5848 - val_acc: 0.6870\n",
      "Epoch 152/1000\n",
      "537/537 [==============================] - 0s 81us/step - loss: 0.6038 - acc: 0.6816 - val_loss: 0.5867 - val_acc: 0.6783\n",
      "Epoch 153/1000\n",
      "537/537 [==============================] - 0s 83us/step - loss: 0.6092 - acc: 0.6760 - val_loss: 0.5842 - val_acc: 0.6870\n",
      "Epoch 154/1000\n",
      "537/537 [==============================] - 0s 88us/step - loss: 0.6111 - acc: 0.6629 - val_loss: 0.5841 - val_acc: 0.6696\n",
      "Epoch 155/1000\n",
      "537/537 [==============================] - 0s 87us/step - loss: 0.6187 - acc: 0.6723 - val_loss: 0.5864 - val_acc: 0.6783\n",
      "Epoch 156/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.5997 - acc: 0.6965 - val_loss: 0.5912 - val_acc: 0.6696\n",
      "Epoch 157/1000\n",
      "537/537 [==============================] - 0s 76us/step - loss: 0.6316 - acc: 0.6555 - val_loss: 0.5893 - val_acc: 0.6870\n",
      "Epoch 158/1000\n",
      "537/537 [==============================] - 0s 77us/step - loss: 0.6146 - acc: 0.6685 - val_loss: 0.5909 - val_acc: 0.6783\n",
      "Epoch 159/1000\n",
      "537/537 [==============================] - 0s 76us/step - loss: 0.6193 - acc: 0.6853 - val_loss: 0.5918 - val_acc: 0.6783\n",
      "Epoch 160/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.6211 - acc: 0.6685 - val_loss: 0.5870 - val_acc: 0.6783\n",
      "Epoch 161/1000\n",
      "537/537 [==============================] - 0s 76us/step - loss: 0.6167 - acc: 0.6760 - val_loss: 0.5919 - val_acc: 0.6870\n",
      "Epoch 162/1000\n",
      "537/537 [==============================] - 0s 77us/step - loss: 0.6194 - acc: 0.6704 - val_loss: 0.5921 - val_acc: 0.6696\n",
      "Epoch 163/1000\n",
      "537/537 [==============================] - 0s 77us/step - loss: 0.6154 - acc: 0.6741 - val_loss: 0.5934 - val_acc: 0.6696\n",
      "Epoch 164/1000\n",
      "537/537 [==============================] - 0s 80us/step - loss: 0.6005 - acc: 0.6872 - val_loss: 0.5835 - val_acc: 0.6870\n",
      "Epoch 165/1000\n",
      "537/537 [==============================] - 0s 80us/step - loss: 0.6146 - acc: 0.6797 - val_loss: 0.5856 - val_acc: 0.6783\n",
      "Epoch 166/1000\n",
      "537/537 [==============================] - 0s 79us/step - loss: 0.6327 - acc: 0.6760 - val_loss: 0.5895 - val_acc: 0.6696\n",
      "Epoch 167/1000\n",
      "537/537 [==============================] - 0s 84us/step - loss: 0.6100 - acc: 0.6778 - val_loss: 0.5957 - val_acc: 0.6783\n",
      "Epoch 168/1000\n",
      "537/537 [==============================] - 0s 76us/step - loss: 0.6012 - acc: 0.6760 - val_loss: 0.5908 - val_acc: 0.6783\n",
      "Epoch 169/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.5989 - acc: 0.6834 - val_loss: 0.5912 - val_acc: 0.6870\n",
      "Epoch 170/1000\n",
      "537/537 [==============================] - 0s 76us/step - loss: 0.6248 - acc: 0.6667 - val_loss: 0.5913 - val_acc: 0.6696\n",
      "Epoch 171/1000\n",
      "537/537 [==============================] - 0s 79us/step - loss: 0.6079 - acc: 0.6816 - val_loss: 0.5925 - val_acc: 0.6696\n",
      "Epoch 172/1000\n",
      "537/537 [==============================] - 0s 91us/step - loss: 0.6250 - acc: 0.6704 - val_loss: 0.5873 - val_acc: 0.6870\n",
      "Epoch 173/1000\n",
      "537/537 [==============================] - 0s 88us/step - loss: 0.6053 - acc: 0.6648 - val_loss: 0.5926 - val_acc: 0.6696\n",
      "Epoch 174/1000\n",
      "537/537 [==============================] - 0s 82us/step - loss: 0.6370 - acc: 0.6574 - val_loss: 0.5918 - val_acc: 0.6696\n",
      "Epoch 175/1000\n",
      "537/537 [==============================] - 0s 79us/step - loss: 0.6213 - acc: 0.6778 - val_loss: 0.5928 - val_acc: 0.6696\n",
      "Epoch 176/1000\n",
      "537/537 [==============================] - 0s 83us/step - loss: 0.6073 - acc: 0.6946 - val_loss: 0.5930 - val_acc: 0.6696\n",
      "Epoch 177/1000\n",
      "537/537 [==============================] - 0s 82us/step - loss: 0.6027 - acc: 0.6723 - val_loss: 0.5864 - val_acc: 0.6783\n",
      "Epoch 178/1000\n",
      "537/537 [==============================] - 0s 84us/step - loss: 0.6143 - acc: 0.6778 - val_loss: 0.5919 - val_acc: 0.6783\n",
      "Epoch 179/1000\n",
      "537/537 [==============================] - 0s 79us/step - loss: 0.6038 - acc: 0.6872 - val_loss: 0.5915 - val_acc: 0.6783\n",
      "Epoch 180/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.6381 - acc: 0.6629 - val_loss: 0.5926 - val_acc: 0.6783\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181/1000\n",
      "537/537 [==============================] - 0s 91us/step - loss: 0.6207 - acc: 0.6797 - val_loss: 0.5939 - val_acc: 0.6696\n",
      "Epoch 182/1000\n",
      "537/537 [==============================] - 0s 96us/step - loss: 0.6148 - acc: 0.6704 - val_loss: 0.5904 - val_acc: 0.6696\n",
      "Epoch 183/1000\n",
      "537/537 [==============================] - 0s 122us/step - loss: 0.6080 - acc: 0.6741 - val_loss: 0.5901 - val_acc: 0.6696\n",
      "Epoch 184/1000\n",
      "537/537 [==============================] - 0s 84us/step - loss: 0.6141 - acc: 0.6723 - val_loss: 0.5963 - val_acc: 0.6696\n",
      "Epoch 185/1000\n",
      "537/537 [==============================] - 0s 84us/step - loss: 0.5996 - acc: 0.6778 - val_loss: 0.5916 - val_acc: 0.6696\n",
      "Epoch 186/1000\n",
      "537/537 [==============================] - 0s 82us/step - loss: 0.6258 - acc: 0.6797 - val_loss: 0.5881 - val_acc: 0.6870\n",
      "Epoch 187/1000\n",
      "537/537 [==============================] - 0s 84us/step - loss: 0.6157 - acc: 0.6760 - val_loss: 0.5930 - val_acc: 0.6696\n",
      "Epoch 188/1000\n",
      "537/537 [==============================] - 0s 91us/step - loss: 0.6131 - acc: 0.6816 - val_loss: 0.5936 - val_acc: 0.6696\n",
      "Epoch 189/1000\n",
      "537/537 [==============================] - 0s 80us/step - loss: 0.6077 - acc: 0.6704 - val_loss: 0.5912 - val_acc: 0.6696\n",
      "Epoch 190/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.5972 - acc: 0.6797 - val_loss: 0.5948 - val_acc: 0.6696\n",
      "Epoch 191/1000\n",
      "537/537 [==============================] - 0s 77us/step - loss: 0.6173 - acc: 0.6741 - val_loss: 0.6009 - val_acc: 0.6609\n",
      "Epoch 192/1000\n",
      "537/537 [==============================] - 0s 74us/step - loss: 0.6269 - acc: 0.6667 - val_loss: 0.5925 - val_acc: 0.6696\n",
      "Epoch 193/1000\n",
      "537/537 [==============================] - 0s 89us/step - loss: 0.6037 - acc: 0.6965 - val_loss: 0.5872 - val_acc: 0.6696\n",
      "Epoch 194/1000\n",
      "537/537 [==============================] - 0s 85us/step - loss: 0.6206 - acc: 0.6741 - val_loss: 0.5874 - val_acc: 0.6783\n",
      "Epoch 195/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.6163 - acc: 0.6723 - val_loss: 0.5905 - val_acc: 0.6870\n",
      "Epoch 196/1000\n",
      "537/537 [==============================] - 0s 81us/step - loss: 0.6054 - acc: 0.6834 - val_loss: 0.5843 - val_acc: 0.7043\n",
      "Epoch 197/1000\n",
      "537/537 [==============================] - 0s 77us/step - loss: 0.6082 - acc: 0.6685 - val_loss: 0.5843 - val_acc: 0.6870\n",
      "Epoch 198/1000\n",
      "537/537 [==============================] - 0s 81us/step - loss: 0.6079 - acc: 0.6797 - val_loss: 0.5919 - val_acc: 0.6870\n",
      "Epoch 199/1000\n",
      "537/537 [==============================] - 0s 79us/step - loss: 0.5980 - acc: 0.6872 - val_loss: 0.5872 - val_acc: 0.6870\n",
      "Epoch 200/1000\n",
      "537/537 [==============================] - 0s 80us/step - loss: 0.5960 - acc: 0.6890 - val_loss: 0.5822 - val_acc: 0.6783\n",
      "Epoch 201/1000\n",
      "537/537 [==============================] - 0s 86us/step - loss: 0.5920 - acc: 0.6797 - val_loss: 0.5805 - val_acc: 0.6783\n",
      "Epoch 202/1000\n",
      "537/537 [==============================] - 0s 84us/step - loss: 0.6036 - acc: 0.6760 - val_loss: 0.5853 - val_acc: 0.6870\n",
      "Epoch 203/1000\n",
      "537/537 [==============================] - 0s 80us/step - loss: 0.6025 - acc: 0.7039 - val_loss: 0.5869 - val_acc: 0.6957\n",
      "Epoch 204/1000\n",
      "537/537 [==============================] - 0s 81us/step - loss: 0.6109 - acc: 0.6723 - val_loss: 0.5894 - val_acc: 0.7043\n",
      "Epoch 205/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.5994 - acc: 0.6890 - val_loss: 0.5892 - val_acc: 0.6957\n",
      "Epoch 206/1000\n",
      "537/537 [==============================] - 0s 75us/step - loss: 0.6106 - acc: 0.6834 - val_loss: 0.5928 - val_acc: 0.6957\n",
      "Epoch 207/1000\n",
      "537/537 [==============================] - 0s 79us/step - loss: 0.6041 - acc: 0.6648 - val_loss: 0.5950 - val_acc: 0.6870\n",
      "Epoch 208/1000\n",
      "537/537 [==============================] - 0s 76us/step - loss: 0.5947 - acc: 0.6872 - val_loss: 0.5911 - val_acc: 0.6783\n",
      "Epoch 209/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.6187 - acc: 0.6816 - val_loss: 0.5906 - val_acc: 0.6696\n",
      "Epoch 210/1000\n",
      "537/537 [==============================] - 0s 83us/step - loss: 0.5938 - acc: 0.7095 - val_loss: 0.5908 - val_acc: 0.6957\n",
      "Epoch 211/1000\n",
      "537/537 [==============================] - 0s 80us/step - loss: 0.6130 - acc: 0.6927 - val_loss: 0.5900 - val_acc: 0.6957\n",
      "Epoch 212/1000\n",
      "537/537 [==============================] - 0s 93us/step - loss: 0.6118 - acc: 0.6872 - val_loss: 0.5944 - val_acc: 0.6783\n",
      "Epoch 213/1000\n",
      "537/537 [==============================] - 0s 95us/step - loss: 0.5930 - acc: 0.6927 - val_loss: 0.5902 - val_acc: 0.6957\n",
      "Epoch 214/1000\n",
      "537/537 [==============================] - 0s 81us/step - loss: 0.5976 - acc: 0.6797 - val_loss: 0.5853 - val_acc: 0.6870\n",
      "Epoch 215/1000\n",
      "537/537 [==============================] - 0s 91us/step - loss: 0.6026 - acc: 0.6853 - val_loss: 0.5838 - val_acc: 0.7130\n",
      "Epoch 216/1000\n",
      "537/537 [==============================] - 0s 95us/step - loss: 0.5964 - acc: 0.6890 - val_loss: 0.5884 - val_acc: 0.6783\n",
      "Epoch 217/1000\n",
      "537/537 [==============================] - 0s 84us/step - loss: 0.5982 - acc: 0.6853 - val_loss: 0.5883 - val_acc: 0.6870\n",
      "Epoch 218/1000\n",
      "537/537 [==============================] - 0s 81us/step - loss: 0.6188 - acc: 0.6629 - val_loss: 0.5944 - val_acc: 0.6870\n",
      "Epoch 219/1000\n",
      "537/537 [==============================] - 0s 81us/step - loss: 0.6121 - acc: 0.6760 - val_loss: 0.5981 - val_acc: 0.6870\n",
      "Epoch 220/1000\n",
      "537/537 [==============================] - 0s 80us/step - loss: 0.6044 - acc: 0.6853 - val_loss: 0.5979 - val_acc: 0.6783\n",
      "Epoch 221/1000\n",
      "537/537 [==============================] - 0s 82us/step - loss: 0.5920 - acc: 0.6816 - val_loss: 0.5890 - val_acc: 0.6870\n",
      "Epoch 222/1000\n",
      "537/537 [==============================] - 0s 83us/step - loss: 0.6079 - acc: 0.6592 - val_loss: 0.5913 - val_acc: 0.6870\n",
      "Epoch 223/1000\n",
      "537/537 [==============================] - 0s 80us/step - loss: 0.6155 - acc: 0.6611 - val_loss: 0.5956 - val_acc: 0.6696\n",
      "Epoch 224/1000\n",
      "537/537 [==============================] - 0s 80us/step - loss: 0.5968 - acc: 0.6909 - val_loss: 0.5838 - val_acc: 0.7043\n",
      "Epoch 225/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.5935 - acc: 0.6797 - val_loss: 0.5857 - val_acc: 0.6957\n",
      "Epoch 226/1000\n",
      "537/537 [==============================] - 0s 76us/step - loss: 0.6049 - acc: 0.6816 - val_loss: 0.5915 - val_acc: 0.6957\n",
      "Epoch 227/1000\n",
      "537/537 [==============================] - 0s 75us/step - loss: 0.5903 - acc: 0.6853 - val_loss: 0.5871 - val_acc: 0.6957\n",
      "Epoch 228/1000\n",
      "537/537 [==============================] - 0s 76us/step - loss: 0.5872 - acc: 0.6946 - val_loss: 0.5824 - val_acc: 0.6957\n",
      "Epoch 229/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.6225 - acc: 0.6611 - val_loss: 0.5931 - val_acc: 0.6870\n",
      "Epoch 230/1000\n",
      "537/537 [==============================] - 0s 76us/step - loss: 0.6182 - acc: 0.6723 - val_loss: 0.6068 - val_acc: 0.6783\n",
      "Epoch 231/1000\n",
      "537/537 [==============================] - 0s 82us/step - loss: 0.5931 - acc: 0.6983 - val_loss: 0.5967 - val_acc: 0.6696\n",
      "Epoch 232/1000\n",
      "537/537 [==============================] - 0s 76us/step - loss: 0.6091 - acc: 0.6816 - val_loss: 0.5953 - val_acc: 0.6696\n",
      "Epoch 233/1000\n",
      "537/537 [==============================] - 0s 80us/step - loss: 0.5859 - acc: 0.6965 - val_loss: 0.5892 - val_acc: 0.6696\n",
      "Epoch 234/1000\n",
      "537/537 [==============================] - 0s 72us/step - loss: 0.6208 - acc: 0.6741 - val_loss: 0.5909 - val_acc: 0.6696\n",
      "Epoch 235/1000\n",
      "537/537 [==============================] - 0s 85us/step - loss: 0.6166 - acc: 0.6723 - val_loss: 0.5946 - val_acc: 0.6696\n",
      "Epoch 236/1000\n",
      "537/537 [==============================] - 0s 77us/step - loss: 0.6011 - acc: 0.6983 - val_loss: 0.5942 - val_acc: 0.6696\n",
      "Epoch 237/1000\n",
      "537/537 [==============================] - 0s 79us/step - loss: 0.6078 - acc: 0.6853 - val_loss: 0.5916 - val_acc: 0.6696\n",
      "Epoch 238/1000\n",
      "537/537 [==============================] - 0s 75us/step - loss: 0.5936 - acc: 0.6834 - val_loss: 0.5859 - val_acc: 0.6783\n",
      "Epoch 239/1000\n",
      "537/537 [==============================] - 0s 77us/step - loss: 0.6073 - acc: 0.6834 - val_loss: 0.5816 - val_acc: 0.7043\n",
      "Epoch 240/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.6028 - acc: 0.6834 - val_loss: 0.5829 - val_acc: 0.6783\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 241/1000\n",
      "537/537 [==============================] - 0s 81us/step - loss: 0.6097 - acc: 0.6667 - val_loss: 0.5899 - val_acc: 0.6696\n",
      "Epoch 242/1000\n",
      "537/537 [==============================] - 0s 76us/step - loss: 0.6160 - acc: 0.6797 - val_loss: 0.5884 - val_acc: 0.6957\n",
      "Epoch 243/1000\n",
      "537/537 [==============================] - 0s 76us/step - loss: 0.6097 - acc: 0.6667 - val_loss: 0.5945 - val_acc: 0.6783\n",
      "Epoch 244/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.5967 - acc: 0.6834 - val_loss: 0.5863 - val_acc: 0.6870\n",
      "Epoch 245/1000\n",
      "537/537 [==============================] - 0s 83us/step - loss: 0.6044 - acc: 0.6778 - val_loss: 0.5772 - val_acc: 0.6696\n",
      "Epoch 246/1000\n",
      "537/537 [==============================] - 0s 84us/step - loss: 0.6040 - acc: 0.6685 - val_loss: 0.5790 - val_acc: 0.6870\n",
      "Epoch 247/1000\n",
      "537/537 [==============================] - 0s 81us/step - loss: 0.6123 - acc: 0.6778 - val_loss: 0.5810 - val_acc: 0.7043\n",
      "Epoch 248/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.5927 - acc: 0.6704 - val_loss: 0.5822 - val_acc: 0.6870\n",
      "Epoch 249/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.5990 - acc: 0.6741 - val_loss: 0.5828 - val_acc: 0.6870\n",
      "Epoch 250/1000\n",
      "537/537 [==============================] - 0s 79us/step - loss: 0.6111 - acc: 0.6816 - val_loss: 0.5809 - val_acc: 0.6870\n",
      "Epoch 251/1000\n",
      "537/537 [==============================] - 0s 76us/step - loss: 0.5945 - acc: 0.6909 - val_loss: 0.5812 - val_acc: 0.7217\n",
      "Epoch 252/1000\n",
      "537/537 [==============================] - 0s 77us/step - loss: 0.6046 - acc: 0.6853 - val_loss: 0.5857 - val_acc: 0.6870\n",
      "Epoch 253/1000\n",
      "537/537 [==============================] - 0s 76us/step - loss: 0.5987 - acc: 0.7020 - val_loss: 0.5835 - val_acc: 0.6870\n",
      "Epoch 254/1000\n",
      "537/537 [==============================] - 0s 80us/step - loss: 0.6127 - acc: 0.6797 - val_loss: 0.5907 - val_acc: 0.7130\n",
      "Epoch 255/1000\n",
      "537/537 [==============================] - 0s 76us/step - loss: 0.6083 - acc: 0.6890 - val_loss: 0.5868 - val_acc: 0.7043\n",
      "Epoch 256/1000\n",
      "537/537 [==============================] - 0s 82us/step - loss: 0.5984 - acc: 0.6872 - val_loss: 0.5890 - val_acc: 0.7043\n",
      "Epoch 257/1000\n",
      "537/537 [==============================] - 0s 77us/step - loss: 0.6062 - acc: 0.6890 - val_loss: 0.5896 - val_acc: 0.6870\n",
      "Epoch 258/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.6094 - acc: 0.6834 - val_loss: 0.5877 - val_acc: 0.6957\n",
      "Epoch 259/1000\n",
      "537/537 [==============================] - 0s 79us/step - loss: 0.5848 - acc: 0.7002 - val_loss: 0.5826 - val_acc: 0.7043\n",
      "Epoch 260/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.6024 - acc: 0.6872 - val_loss: 0.5748 - val_acc: 0.7217\n",
      "Epoch 261/1000\n",
      "537/537 [==============================] - 0s 75us/step - loss: 0.6046 - acc: 0.6946 - val_loss: 0.5781 - val_acc: 0.7130\n",
      "Epoch 262/1000\n",
      "537/537 [==============================] - 0s 80us/step - loss: 0.6187 - acc: 0.6536 - val_loss: 0.5811 - val_acc: 0.6783\n",
      "Epoch 263/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.5854 - acc: 0.7002 - val_loss: 0.5775 - val_acc: 0.6783\n",
      "Epoch 264/1000\n",
      "537/537 [==============================] - 0s 83us/step - loss: 0.6072 - acc: 0.6816 - val_loss: 0.5833 - val_acc: 0.6783\n",
      "Epoch 265/1000\n",
      "537/537 [==============================] - 0s 81us/step - loss: 0.5977 - acc: 0.6834 - val_loss: 0.5772 - val_acc: 0.6957\n",
      "Epoch 266/1000\n",
      "537/537 [==============================] - 0s 86us/step - loss: 0.6003 - acc: 0.6853 - val_loss: 0.5778 - val_acc: 0.6957\n",
      "Epoch 267/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.5993 - acc: 0.6890 - val_loss: 0.5780 - val_acc: 0.6957\n",
      "Epoch 268/1000\n",
      "537/537 [==============================] - 0s 84us/step - loss: 0.5915 - acc: 0.6927 - val_loss: 0.5787 - val_acc: 0.6870\n",
      "Epoch 269/1000\n",
      "537/537 [==============================] - 0s 80us/step - loss: 0.5878 - acc: 0.7002 - val_loss: 0.5706 - val_acc: 0.7043\n",
      "Epoch 270/1000\n",
      "537/537 [==============================] - 0s 87us/step - loss: 0.6175 - acc: 0.6816 - val_loss: 0.5775 - val_acc: 0.6957\n",
      "Epoch 271/1000\n",
      "537/537 [==============================] - 0s 89us/step - loss: 0.5997 - acc: 0.6927 - val_loss: 0.5765 - val_acc: 0.6957\n",
      "Epoch 272/1000\n",
      "537/537 [==============================] - 0s 83us/step - loss: 0.5978 - acc: 0.6834 - val_loss: 0.5745 - val_acc: 0.6957\n",
      "Epoch 273/1000\n",
      "537/537 [==============================] - 0s 81us/step - loss: 0.5920 - acc: 0.6816 - val_loss: 0.5797 - val_acc: 0.6783\n",
      "Epoch 274/1000\n",
      "537/537 [==============================] - 0s 76us/step - loss: 0.6001 - acc: 0.6946 - val_loss: 0.5751 - val_acc: 0.6957\n",
      "Epoch 275/1000\n",
      "537/537 [==============================] - 0s 81us/step - loss: 0.6141 - acc: 0.6872 - val_loss: 0.5851 - val_acc: 0.6957\n",
      "Epoch 276/1000\n",
      "537/537 [==============================] - 0s 77us/step - loss: 0.5948 - acc: 0.6965 - val_loss: 0.5820 - val_acc: 0.6870\n",
      "Epoch 277/1000\n",
      "537/537 [==============================] - 0s 79us/step - loss: 0.5942 - acc: 0.6797 - val_loss: 0.5805 - val_acc: 0.7043\n",
      "Epoch 278/1000\n",
      "537/537 [==============================] - 0s 81us/step - loss: 0.5851 - acc: 0.6983 - val_loss: 0.5787 - val_acc: 0.7043\n",
      "Epoch 279/1000\n",
      "537/537 [==============================] - 0s 84us/step - loss: 0.6043 - acc: 0.6816 - val_loss: 0.5798 - val_acc: 0.7043\n",
      "Epoch 280/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.6026 - acc: 0.6872 - val_loss: 0.5758 - val_acc: 0.7043\n",
      "Epoch 281/1000\n",
      "537/537 [==============================] - 0s 79us/step - loss: 0.5780 - acc: 0.7039 - val_loss: 0.5704 - val_acc: 0.7130\n",
      "Epoch 282/1000\n",
      "537/537 [==============================] - 0s 83us/step - loss: 0.5835 - acc: 0.6834 - val_loss: 0.5667 - val_acc: 0.7130\n",
      "Epoch 283/1000\n",
      "537/537 [==============================] - 0s 82us/step - loss: 0.5935 - acc: 0.6890 - val_loss: 0.5717 - val_acc: 0.7130\n",
      "Epoch 284/1000\n",
      "537/537 [==============================] - 0s 76us/step - loss: 0.5868 - acc: 0.6946 - val_loss: 0.5691 - val_acc: 0.7043\n",
      "Epoch 285/1000\n",
      "537/537 [==============================] - 0s 79us/step - loss: 0.6122 - acc: 0.6685 - val_loss: 0.5844 - val_acc: 0.6957\n",
      "Epoch 286/1000\n",
      "537/537 [==============================] - 0s 86us/step - loss: 0.5907 - acc: 0.6983 - val_loss: 0.5759 - val_acc: 0.6957\n",
      "Epoch 287/1000\n",
      "537/537 [==============================] - 0s 87us/step - loss: 0.6004 - acc: 0.6853 - val_loss: 0.5728 - val_acc: 0.7043\n",
      "Epoch 288/1000\n",
      "537/537 [==============================] - 0s 79us/step - loss: 0.5857 - acc: 0.6965 - val_loss: 0.5691 - val_acc: 0.6957\n",
      "Epoch 289/1000\n",
      "537/537 [==============================] - 0s 76us/step - loss: 0.5992 - acc: 0.6983 - val_loss: 0.5737 - val_acc: 0.6957\n",
      "Epoch 290/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.5800 - acc: 0.6890 - val_loss: 0.5750 - val_acc: 0.7043\n",
      "Epoch 291/1000\n",
      "537/537 [==============================] - 0s 93us/step - loss: 0.5967 - acc: 0.6853 - val_loss: 0.5806 - val_acc: 0.7043\n",
      "Epoch 292/1000\n",
      "537/537 [==============================] - 0s 80us/step - loss: 0.5900 - acc: 0.6872 - val_loss: 0.5809 - val_acc: 0.6957\n",
      "Epoch 293/1000\n",
      "537/537 [==============================] - 0s 79us/step - loss: 0.5998 - acc: 0.6778 - val_loss: 0.5860 - val_acc: 0.6870\n",
      "Epoch 294/1000\n",
      "537/537 [==============================] - 0s 76us/step - loss: 0.6005 - acc: 0.7020 - val_loss: 0.5821 - val_acc: 0.7043\n",
      "Epoch 295/1000\n",
      "537/537 [==============================] - 0s 80us/step - loss: 0.6227 - acc: 0.6667 - val_loss: 0.5913 - val_acc: 0.6783\n",
      "Epoch 296/1000\n",
      "537/537 [==============================] - 0s 80us/step - loss: 0.5986 - acc: 0.6778 - val_loss: 0.5862 - val_acc: 0.6870\n",
      "Epoch 297/1000\n",
      "537/537 [==============================] - 0s 113us/step - loss: 0.6017 - acc: 0.6834 - val_loss: 0.5772 - val_acc: 0.6957\n",
      "Epoch 298/1000\n",
      "537/537 [==============================] - 0s 81us/step - loss: 0.5936 - acc: 0.6816 - val_loss: 0.5720 - val_acc: 0.6957\n",
      "Epoch 299/1000\n",
      "537/537 [==============================] - 0s 82us/step - loss: 0.5803 - acc: 0.7020 - val_loss: 0.5712 - val_acc: 0.6957\n",
      "Epoch 300/1000\n",
      "537/537 [==============================] - 0s 80us/step - loss: 0.6142 - acc: 0.6760 - val_loss: 0.5759 - val_acc: 0.6957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 301/1000\n",
      "537/537 [==============================] - 0s 132us/step - loss: 0.5979 - acc: 0.6890 - val_loss: 0.5752 - val_acc: 0.6870\n",
      "Epoch 302/1000\n",
      "537/537 [==============================] - 0s 97us/step - loss: 0.5818 - acc: 0.6834 - val_loss: 0.5674 - val_acc: 0.7130\n",
      "Epoch 303/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.6195 - acc: 0.6611 - val_loss: 0.5743 - val_acc: 0.6870\n",
      "Epoch 304/1000\n",
      "537/537 [==============================] - 0s 84us/step - loss: 0.6012 - acc: 0.6723 - val_loss: 0.5758 - val_acc: 0.6957\n",
      "Epoch 305/1000\n",
      "537/537 [==============================] - 0s 95us/step - loss: 0.6087 - acc: 0.6816 - val_loss: 0.5767 - val_acc: 0.6870\n",
      "Epoch 306/1000\n",
      "537/537 [==============================] - 0s 90us/step - loss: 0.5928 - acc: 0.6890 - val_loss: 0.5724 - val_acc: 0.6870\n",
      "Epoch 307/1000\n",
      "537/537 [==============================] - 0s 83us/step - loss: 0.6008 - acc: 0.6834 - val_loss: 0.5748 - val_acc: 0.6957\n",
      "Epoch 308/1000\n",
      "537/537 [==============================] - 0s 80us/step - loss: 0.5938 - acc: 0.6946 - val_loss: 0.5798 - val_acc: 0.6870\n",
      "Epoch 309/1000\n",
      "537/537 [==============================] - 0s 88us/step - loss: 0.5918 - acc: 0.6983 - val_loss: 0.5772 - val_acc: 0.7043\n",
      "Epoch 310/1000\n",
      "537/537 [==============================] - 0s 80us/step - loss: 0.5986 - acc: 0.6760 - val_loss: 0.5771 - val_acc: 0.6870\n",
      "Epoch 311/1000\n",
      "537/537 [==============================] - 0s 77us/step - loss: 0.5846 - acc: 0.6909 - val_loss: 0.5761 - val_acc: 0.7043\n",
      "Epoch 312/1000\n",
      "537/537 [==============================] - 0s 83us/step - loss: 0.5894 - acc: 0.7095 - val_loss: 0.5734 - val_acc: 0.6957\n",
      "Epoch 313/1000\n",
      "537/537 [==============================] - 0s 80us/step - loss: 0.5789 - acc: 0.7151 - val_loss: 0.5700 - val_acc: 0.7304\n",
      "Epoch 314/1000\n",
      "537/537 [==============================] - 0s 79us/step - loss: 0.5812 - acc: 0.7095 - val_loss: 0.5773 - val_acc: 0.7043\n",
      "Epoch 315/1000\n",
      "537/537 [==============================] - 0s 76us/step - loss: 0.6051 - acc: 0.6890 - val_loss: 0.5783 - val_acc: 0.6957\n",
      "Epoch 316/1000\n",
      "537/537 [==============================] - 0s 80us/step - loss: 0.5849 - acc: 0.6834 - val_loss: 0.5744 - val_acc: 0.7043\n",
      "Epoch 317/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.6034 - acc: 0.6927 - val_loss: 0.5718 - val_acc: 0.7217\n",
      "Epoch 318/1000\n",
      "537/537 [==============================] - 0s 74us/step - loss: 0.5929 - acc: 0.6983 - val_loss: 0.5795 - val_acc: 0.6870\n",
      "Epoch 319/1000\n",
      "537/537 [==============================] - 0s 74us/step - loss: 0.5839 - acc: 0.7076 - val_loss: 0.5774 - val_acc: 0.6957\n",
      "Epoch 320/1000\n",
      "537/537 [==============================] - 0s 79us/step - loss: 0.6064 - acc: 0.6834 - val_loss: 0.5811 - val_acc: 0.6957\n",
      "Epoch 321/1000\n",
      "537/537 [==============================] - 0s 79us/step - loss: 0.6104 - acc: 0.6723 - val_loss: 0.5836 - val_acc: 0.6957\n",
      "Epoch 322/1000\n",
      "537/537 [==============================] - 0s 88us/step - loss: 0.5915 - acc: 0.6909 - val_loss: 0.5819 - val_acc: 0.6957\n",
      "Epoch 323/1000\n",
      "537/537 [==============================] - 0s 79us/step - loss: 0.5965 - acc: 0.6760 - val_loss: 0.5775 - val_acc: 0.6957\n",
      "Epoch 324/1000\n",
      "537/537 [==============================] - 0s 77us/step - loss: 0.6064 - acc: 0.6983 - val_loss: 0.5813 - val_acc: 0.7130\n",
      "Epoch 325/1000\n",
      "537/537 [==============================] - 0s 79us/step - loss: 0.5881 - acc: 0.7039 - val_loss: 0.5789 - val_acc: 0.7043\n",
      "Epoch 326/1000\n",
      "537/537 [==============================] - 0s 77us/step - loss: 0.5964 - acc: 0.6760 - val_loss: 0.5773 - val_acc: 0.6783\n",
      "Epoch 327/1000\n",
      "537/537 [==============================] - 0s 75us/step - loss: 0.5996 - acc: 0.6872 - val_loss: 0.5780 - val_acc: 0.7043\n",
      "Epoch 328/1000\n",
      "537/537 [==============================] - 0s 85us/step - loss: 0.5837 - acc: 0.7002 - val_loss: 0.5807 - val_acc: 0.6783\n",
      "Epoch 329/1000\n",
      "537/537 [==============================] - 0s 80us/step - loss: 0.5836 - acc: 0.6946 - val_loss: 0.5772 - val_acc: 0.7043\n",
      "Epoch 330/1000\n",
      "537/537 [==============================] - 0s 82us/step - loss: 0.5929 - acc: 0.6723 - val_loss: 0.5775 - val_acc: 0.6783\n",
      "Epoch 331/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.5849 - acc: 0.6909 - val_loss: 0.5788 - val_acc: 0.6957\n",
      "Epoch 332/1000\n",
      "537/537 [==============================] - 0s 74us/step - loss: 0.5948 - acc: 0.6778 - val_loss: 0.5770 - val_acc: 0.7130\n",
      "Epoch 333/1000\n",
      "537/537 [==============================] - 0s 75us/step - loss: 0.6036 - acc: 0.6685 - val_loss: 0.5767 - val_acc: 0.6957\n",
      "Epoch 334/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.5746 - acc: 0.7002 - val_loss: 0.5740 - val_acc: 0.7043\n",
      "Epoch 335/1000\n",
      "537/537 [==============================] - 0s 77us/step - loss: 0.5893 - acc: 0.6946 - val_loss: 0.5748 - val_acc: 0.7130\n",
      "Epoch 336/1000\n",
      "537/537 [==============================] - 0s 88us/step - loss: 0.5905 - acc: 0.6816 - val_loss: 0.5746 - val_acc: 0.7043\n",
      "Epoch 337/1000\n",
      "537/537 [==============================] - 0s 76us/step - loss: 0.5982 - acc: 0.6927 - val_loss: 0.5820 - val_acc: 0.7043\n",
      "Epoch 338/1000\n",
      "537/537 [==============================] - 0s 81us/step - loss: 0.5940 - acc: 0.6983 - val_loss: 0.5851 - val_acc: 0.6870\n",
      "Epoch 339/1000\n",
      "537/537 [==============================] - 0s 82us/step - loss: 0.5799 - acc: 0.6927 - val_loss: 0.5787 - val_acc: 0.7217\n",
      "Epoch 340/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.5891 - acc: 0.7114 - val_loss: 0.5797 - val_acc: 0.7130\n",
      "Epoch 341/1000\n",
      "537/537 [==============================] - 0s 75us/step - loss: 0.5927 - acc: 0.7039 - val_loss: 0.5828 - val_acc: 0.7130\n",
      "Epoch 342/1000\n",
      "537/537 [==============================] - 0s 85us/step - loss: 0.5961 - acc: 0.6965 - val_loss: 0.5818 - val_acc: 0.7043\n",
      "Epoch 343/1000\n",
      "537/537 [==============================] - 0s 82us/step - loss: 0.5765 - acc: 0.7076 - val_loss: 0.5796 - val_acc: 0.7043\n",
      "Epoch 344/1000\n",
      "537/537 [==============================] - 0s 82us/step - loss: 0.5861 - acc: 0.6946 - val_loss: 0.5753 - val_acc: 0.7043\n",
      "Epoch 345/1000\n",
      "537/537 [==============================] - 0s 80us/step - loss: 0.5898 - acc: 0.6778 - val_loss: 0.5833 - val_acc: 0.7043\n",
      "Epoch 346/1000\n",
      "537/537 [==============================] - 0s 84us/step - loss: 0.5782 - acc: 0.6965 - val_loss: 0.5780 - val_acc: 0.7043\n",
      "Epoch 347/1000\n",
      "537/537 [==============================] - 0s 80us/step - loss: 0.5847 - acc: 0.6965 - val_loss: 0.5735 - val_acc: 0.7043\n",
      "Epoch 348/1000\n",
      "537/537 [==============================] - 0s 81us/step - loss: 0.5954 - acc: 0.6927 - val_loss: 0.5794 - val_acc: 0.7043\n",
      "Epoch 349/1000\n",
      "537/537 [==============================] - 0s 82us/step - loss: 0.5747 - acc: 0.7058 - val_loss: 0.5770 - val_acc: 0.7130\n",
      "Epoch 350/1000\n",
      "537/537 [==============================] - 0s 76us/step - loss: 0.6124 - acc: 0.6685 - val_loss: 0.5794 - val_acc: 0.6957\n",
      "Epoch 351/1000\n",
      "537/537 [==============================] - 0s 74us/step - loss: 0.5881 - acc: 0.6946 - val_loss: 0.5838 - val_acc: 0.7043\n",
      "Epoch 352/1000\n",
      "537/537 [==============================] - 0s 76us/step - loss: 0.5859 - acc: 0.6872 - val_loss: 0.5712 - val_acc: 0.6957\n",
      "Epoch 353/1000\n",
      "537/537 [==============================] - 0s 79us/step - loss: 0.5938 - acc: 0.6704 - val_loss: 0.5758 - val_acc: 0.6870\n",
      "Epoch 354/1000\n",
      "537/537 [==============================] - 0s 74us/step - loss: 0.5807 - acc: 0.6927 - val_loss: 0.5770 - val_acc: 0.6870\n",
      "Epoch 355/1000\n",
      "537/537 [==============================] - 0s 77us/step - loss: 0.5823 - acc: 0.6872 - val_loss: 0.5765 - val_acc: 0.6957\n",
      "Epoch 356/1000\n",
      "537/537 [==============================] - 0s 75us/step - loss: 0.5945 - acc: 0.6946 - val_loss: 0.5828 - val_acc: 0.6957\n",
      "Epoch 357/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.5857 - acc: 0.7095 - val_loss: 0.5784 - val_acc: 0.7130\n",
      "Epoch 358/1000\n",
      "537/537 [==============================] - 0s 79us/step - loss: 0.5801 - acc: 0.6853 - val_loss: 0.5718 - val_acc: 0.6957\n",
      "Epoch 359/1000\n",
      "537/537 [==============================] - 0s 82us/step - loss: 0.6203 - acc: 0.6760 - val_loss: 0.5757 - val_acc: 0.6957\n",
      "Epoch 360/1000\n",
      "537/537 [==============================] - 0s 82us/step - loss: 0.5931 - acc: 0.6946 - val_loss: 0.5790 - val_acc: 0.6957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 361/1000\n",
      "537/537 [==============================] - 0s 95us/step - loss: 0.5862 - acc: 0.7095 - val_loss: 0.5805 - val_acc: 0.7043\n",
      "Epoch 362/1000\n",
      "537/537 [==============================] - 0s 73us/step - loss: 0.5849 - acc: 0.6909 - val_loss: 0.5712 - val_acc: 0.7130\n",
      "Epoch 363/1000\n",
      "537/537 [==============================] - 0s 108us/step - loss: 0.5903 - acc: 0.6872 - val_loss: 0.5713 - val_acc: 0.7043\n",
      "Epoch 364/1000\n",
      "537/537 [==============================] - 0s 86us/step - loss: 0.5614 - acc: 0.7132 - val_loss: 0.5652 - val_acc: 0.7130\n",
      "Epoch 365/1000\n",
      "537/537 [==============================] - 0s 86us/step - loss: 0.6060 - acc: 0.6797 - val_loss: 0.5755 - val_acc: 0.6957\n",
      "Epoch 366/1000\n",
      "537/537 [==============================] - 0s 79us/step - loss: 0.5802 - acc: 0.6890 - val_loss: 0.5699 - val_acc: 0.6957\n",
      "Epoch 367/1000\n",
      "537/537 [==============================] - 0s 82us/step - loss: 0.5784 - acc: 0.7020 - val_loss: 0.5747 - val_acc: 0.7130\n",
      "Epoch 368/1000\n",
      "537/537 [==============================] - 0s 80us/step - loss: 0.5809 - acc: 0.6927 - val_loss: 0.5752 - val_acc: 0.7130\n",
      "Epoch 369/1000\n",
      "537/537 [==============================] - 0s 82us/step - loss: 0.5679 - acc: 0.7076 - val_loss: 0.5705 - val_acc: 0.7304\n",
      "Epoch 370/1000\n",
      "537/537 [==============================] - 0s 83us/step - loss: 0.5880 - acc: 0.7039 - val_loss: 0.5631 - val_acc: 0.7217\n",
      "Epoch 371/1000\n",
      "537/537 [==============================] - 0s 81us/step - loss: 0.6030 - acc: 0.6741 - val_loss: 0.5728 - val_acc: 0.7217\n",
      "Epoch 372/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.5926 - acc: 0.6927 - val_loss: 0.5658 - val_acc: 0.7217\n",
      "Epoch 373/1000\n",
      "537/537 [==============================] - 0s 77us/step - loss: 0.5658 - acc: 0.7169 - val_loss: 0.5699 - val_acc: 0.7130\n",
      "Epoch 374/1000\n",
      "537/537 [==============================] - 0s 77us/step - loss: 0.5764 - acc: 0.6946 - val_loss: 0.5719 - val_acc: 0.7043\n",
      "Epoch 375/1000\n",
      "537/537 [==============================] - 0s 74us/step - loss: 0.6025 - acc: 0.6834 - val_loss: 0.5801 - val_acc: 0.6957\n",
      "Epoch 376/1000\n",
      "537/537 [==============================] - 0s 74us/step - loss: 0.5888 - acc: 0.6853 - val_loss: 0.5761 - val_acc: 0.7043\n",
      "Epoch 377/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.5826 - acc: 0.7095 - val_loss: 0.5729 - val_acc: 0.6957\n",
      "Epoch 378/1000\n",
      "537/537 [==============================] - 0s 79us/step - loss: 0.5866 - acc: 0.6778 - val_loss: 0.5694 - val_acc: 0.7043\n",
      "Epoch 379/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.5801 - acc: 0.6983 - val_loss: 0.5686 - val_acc: 0.7043\n",
      "Epoch 380/1000\n",
      "537/537 [==============================] - 0s 76us/step - loss: 0.5750 - acc: 0.6909 - val_loss: 0.5657 - val_acc: 0.7130\n",
      "Epoch 381/1000\n",
      "537/537 [==============================] - 0s 82us/step - loss: 0.5803 - acc: 0.7076 - val_loss: 0.5665 - val_acc: 0.7217\n",
      "Epoch 382/1000\n",
      "537/537 [==============================] - 0s 94us/step - loss: 0.5767 - acc: 0.7076 - val_loss: 0.5634 - val_acc: 0.7304\n",
      "Epoch 383/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.6023 - acc: 0.6760 - val_loss: 0.5692 - val_acc: 0.7043\n",
      "Epoch 384/1000\n",
      "537/537 [==============================] - 0s 79us/step - loss: 0.5836 - acc: 0.6909 - val_loss: 0.5647 - val_acc: 0.7043\n",
      "Epoch 385/1000\n",
      "537/537 [==============================] - 0s 79us/step - loss: 0.6038 - acc: 0.7020 - val_loss: 0.5671 - val_acc: 0.7043\n",
      "Epoch 386/1000\n",
      "537/537 [==============================] - 0s 75us/step - loss: 0.5862 - acc: 0.6834 - val_loss: 0.5668 - val_acc: 0.6870\n",
      "Epoch 387/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.5863 - acc: 0.6834 - val_loss: 0.5612 - val_acc: 0.7043\n",
      "Epoch 388/1000\n",
      "537/537 [==============================] - 0s 77us/step - loss: 0.5731 - acc: 0.7002 - val_loss: 0.5613 - val_acc: 0.7043\n",
      "Epoch 389/1000\n",
      "537/537 [==============================] - 0s 76us/step - loss: 0.5832 - acc: 0.6965 - val_loss: 0.5656 - val_acc: 0.7043\n",
      "Epoch 390/1000\n",
      "537/537 [==============================] - 0s 93us/step - loss: 0.5710 - acc: 0.7114 - val_loss: 0.5629 - val_acc: 0.7130\n",
      "Epoch 391/1000\n",
      "537/537 [==============================] - 0s 81us/step - loss: 0.5911 - acc: 0.6983 - val_loss: 0.5693 - val_acc: 0.7130\n",
      "Epoch 392/1000\n",
      "537/537 [==============================] - 0s 76us/step - loss: 0.5701 - acc: 0.7002 - val_loss: 0.5691 - val_acc: 0.7217\n",
      "Epoch 393/1000\n",
      "537/537 [==============================] - 0s 80us/step - loss: 0.5888 - acc: 0.7020 - val_loss: 0.5690 - val_acc: 0.7217\n",
      "Epoch 394/1000\n",
      "537/537 [==============================] - 0s 82us/step - loss: 0.5800 - acc: 0.6965 - val_loss: 0.5715 - val_acc: 0.7217\n",
      "Epoch 395/1000\n",
      "537/537 [==============================] - 0s 79us/step - loss: 0.5748 - acc: 0.6927 - val_loss: 0.5717 - val_acc: 0.7130\n",
      "Epoch 396/1000\n",
      "537/537 [==============================] - 0s 79us/step - loss: 0.5816 - acc: 0.7058 - val_loss: 0.5735 - val_acc: 0.7130\n",
      "Epoch 397/1000\n",
      "537/537 [==============================] - 0s 84us/step - loss: 0.5788 - acc: 0.7076 - val_loss: 0.5727 - val_acc: 0.7217\n",
      "Epoch 398/1000\n",
      "537/537 [==============================] - 0s 79us/step - loss: 0.5874 - acc: 0.7095 - val_loss: 0.5759 - val_acc: 0.7217\n",
      "Epoch 399/1000\n",
      "537/537 [==============================] - 0s 88us/step - loss: 0.5671 - acc: 0.7281 - val_loss: 0.5703 - val_acc: 0.7130\n",
      "Epoch 400/1000\n",
      "537/537 [==============================] - 0s 82us/step - loss: 0.5763 - acc: 0.7020 - val_loss: 0.5611 - val_acc: 0.7130\n",
      "Epoch 401/1000\n",
      "537/537 [==============================] - 0s 79us/step - loss: 0.5818 - acc: 0.7002 - val_loss: 0.5555 - val_acc: 0.7043\n",
      "Epoch 402/1000\n",
      "537/537 [==============================] - 0s 90us/step - loss: 0.5864 - acc: 0.6927 - val_loss: 0.5646 - val_acc: 0.7043\n",
      "Epoch 403/1000\n",
      "537/537 [==============================] - 0s 79us/step - loss: 0.5929 - acc: 0.6946 - val_loss: 0.5645 - val_acc: 0.7130\n",
      "Epoch 404/1000\n",
      "537/537 [==============================] - 0s 87us/step - loss: 0.5894 - acc: 0.7020 - val_loss: 0.5603 - val_acc: 0.7304\n",
      "Epoch 405/1000\n",
      "537/537 [==============================] - 0s 80us/step - loss: 0.5706 - acc: 0.7151 - val_loss: 0.5509 - val_acc: 0.7304\n",
      "Epoch 406/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.5698 - acc: 0.7095 - val_loss: 0.5557 - val_acc: 0.7478\n",
      "Epoch 407/1000\n",
      "537/537 [==============================] - 0s 77us/step - loss: 0.5766 - acc: 0.7076 - val_loss: 0.5549 - val_acc: 0.7304\n",
      "Epoch 408/1000\n",
      "537/537 [==============================] - 0s 75us/step - loss: 0.5907 - acc: 0.6872 - val_loss: 0.5584 - val_acc: 0.7217\n",
      "Epoch 409/1000\n",
      "537/537 [==============================] - 0s 83us/step - loss: 0.5694 - acc: 0.7169 - val_loss: 0.5632 - val_acc: 0.7130\n",
      "Epoch 410/1000\n",
      "537/537 [==============================] - 0s 75us/step - loss: 0.5776 - acc: 0.7039 - val_loss: 0.5589 - val_acc: 0.7217\n",
      "Epoch 411/1000\n",
      "537/537 [==============================] - 0s 77us/step - loss: 0.5831 - acc: 0.6927 - val_loss: 0.5556 - val_acc: 0.7217\n",
      "Epoch 412/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.5757 - acc: 0.7244 - val_loss: 0.5591 - val_acc: 0.7304\n",
      "Epoch 413/1000\n",
      "537/537 [==============================] - 0s 76us/step - loss: 0.5898 - acc: 0.7076 - val_loss: 0.5564 - val_acc: 0.7217\n",
      "Epoch 414/1000\n",
      "537/537 [==============================] - 0s 77us/step - loss: 0.5731 - acc: 0.6909 - val_loss: 0.5576 - val_acc: 0.7217\n",
      "Epoch 415/1000\n",
      "537/537 [==============================] - 0s 80us/step - loss: 0.5697 - acc: 0.7225 - val_loss: 0.5549 - val_acc: 0.7391\n",
      "Epoch 416/1000\n",
      "537/537 [==============================] - 0s 98us/step - loss: 0.5990 - acc: 0.6816 - val_loss: 0.5655 - val_acc: 0.7130\n",
      "Epoch 417/1000\n",
      "537/537 [==============================] - 0s 86us/step - loss: 0.5866 - acc: 0.6778 - val_loss: 0.5569 - val_acc: 0.7217\n",
      "Epoch 418/1000\n",
      "537/537 [==============================] - 0s 82us/step - loss: 0.5691 - acc: 0.7244 - val_loss: 0.5582 - val_acc: 0.7130\n",
      "Epoch 419/1000\n",
      "537/537 [==============================] - 0s 80us/step - loss: 0.5765 - acc: 0.7169 - val_loss: 0.5640 - val_acc: 0.7304\n",
      "Epoch 420/1000\n",
      "537/537 [==============================] - 0s 80us/step - loss: 0.5833 - acc: 0.6965 - val_loss: 0.5610 - val_acc: 0.7130\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 421/1000\n",
      "537/537 [==============================] - 0s 82us/step - loss: 0.5764 - acc: 0.7076 - val_loss: 0.5629 - val_acc: 0.7304\n",
      "Epoch 422/1000\n",
      "537/537 [==============================] - 0s 83us/step - loss: 0.5805 - acc: 0.7039 - val_loss: 0.5593 - val_acc: 0.7130\n",
      "Epoch 423/1000\n",
      "537/537 [==============================] - 0s 81us/step - loss: 0.5909 - acc: 0.6909 - val_loss: 0.5605 - val_acc: 0.7478\n",
      "Epoch 424/1000\n",
      "537/537 [==============================] - 0s 82us/step - loss: 0.5733 - acc: 0.7151 - val_loss: 0.5630 - val_acc: 0.7217\n",
      "Epoch 425/1000\n",
      "537/537 [==============================] - 0s 80us/step - loss: 0.5772 - acc: 0.7002 - val_loss: 0.5657 - val_acc: 0.7217\n",
      "Epoch 426/1000\n",
      "537/537 [==============================] - 0s 84us/step - loss: 0.5941 - acc: 0.6946 - val_loss: 0.5600 - val_acc: 0.7304\n",
      "Epoch 427/1000\n",
      "537/537 [==============================] - 0s 80us/step - loss: 0.5584 - acc: 0.7132 - val_loss: 0.5603 - val_acc: 0.7478\n",
      "Epoch 428/1000\n",
      "537/537 [==============================] - 0s 83us/step - loss: 0.5910 - acc: 0.6946 - val_loss: 0.5648 - val_acc: 0.7130\n",
      "Epoch 429/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.5896 - acc: 0.7076 - val_loss: 0.5674 - val_acc: 0.7043\n",
      "Epoch 430/1000\n",
      "537/537 [==============================] - 0s 80us/step - loss: 0.5782 - acc: 0.7020 - val_loss: 0.5624 - val_acc: 0.7130\n",
      "Epoch 431/1000\n",
      "537/537 [==============================] - 0s 82us/step - loss: 0.5867 - acc: 0.6946 - val_loss: 0.5640 - val_acc: 0.7217\n",
      "Epoch 432/1000\n",
      "537/537 [==============================] - 0s 86us/step - loss: 0.5764 - acc: 0.6927 - val_loss: 0.5623 - val_acc: 0.7304\n",
      "Epoch 433/1000\n",
      "537/537 [==============================] - 0s 81us/step - loss: 0.5597 - acc: 0.7151 - val_loss: 0.5595 - val_acc: 0.7304\n",
      "Epoch 434/1000\n",
      "537/537 [==============================] - 0s 82us/step - loss: 0.5877 - acc: 0.7002 - val_loss: 0.5658 - val_acc: 0.7217\n",
      "Epoch 435/1000\n",
      "537/537 [==============================] - 0s 75us/step - loss: 0.5856 - acc: 0.7020 - val_loss: 0.5648 - val_acc: 0.7217\n",
      "Epoch 436/1000\n",
      "537/537 [==============================] - 0s 75us/step - loss: 0.5919 - acc: 0.6872 - val_loss: 0.5641 - val_acc: 0.7217\n",
      "Epoch 437/1000\n",
      "537/537 [==============================] - 0s 74us/step - loss: 0.6059 - acc: 0.6853 - val_loss: 0.5586 - val_acc: 0.7130\n",
      "Epoch 438/1000\n",
      "537/537 [==============================] - 0s 72us/step - loss: 0.5764 - acc: 0.6983 - val_loss: 0.5544 - val_acc: 0.7304\n",
      "Epoch 439/1000\n",
      "537/537 [==============================] - 0s 76us/step - loss: 0.5846 - acc: 0.6946 - val_loss: 0.5529 - val_acc: 0.7478\n",
      "Epoch 440/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.5810 - acc: 0.7095 - val_loss: 0.5578 - val_acc: 0.7391\n",
      "Epoch 441/1000\n",
      "537/537 [==============================] - 0s 79us/step - loss: 0.5645 - acc: 0.7114 - val_loss: 0.5537 - val_acc: 0.7130\n",
      "Epoch 442/1000\n",
      "537/537 [==============================] - 0s 87us/step - loss: 0.5795 - acc: 0.7095 - val_loss: 0.5524 - val_acc: 0.7391\n",
      "Epoch 443/1000\n",
      "537/537 [==============================] - 0s 74us/step - loss: 0.5954 - acc: 0.6965 - val_loss: 0.5578 - val_acc: 0.7130\n",
      "Epoch 444/1000\n",
      "537/537 [==============================] - 0s 74us/step - loss: 0.5815 - acc: 0.7039 - val_loss: 0.5588 - val_acc: 0.7130\n",
      "Epoch 445/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.5809 - acc: 0.7058 - val_loss: 0.5525 - val_acc: 0.7217\n",
      "Epoch 446/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.5765 - acc: 0.7039 - val_loss: 0.5535 - val_acc: 0.7217\n",
      "Epoch 447/1000\n",
      "537/537 [==============================] - 0s 79us/step - loss: 0.5844 - acc: 0.7002 - val_loss: 0.5474 - val_acc: 0.7391\n",
      "Epoch 448/1000\n",
      "537/537 [==============================] - 0s 80us/step - loss: 0.5910 - acc: 0.7076 - val_loss: 0.5571 - val_acc: 0.7217\n",
      "Epoch 449/1000\n",
      "537/537 [==============================] - 0s 85us/step - loss: 0.5671 - acc: 0.7095 - val_loss: 0.5530 - val_acc: 0.7217\n",
      "Epoch 450/1000\n",
      "537/537 [==============================] - 0s 81us/step - loss: 0.5929 - acc: 0.6927 - val_loss: 0.5548 - val_acc: 0.7304\n",
      "Epoch 451/1000\n",
      "537/537 [==============================] - 0s 86us/step - loss: 0.5822 - acc: 0.6834 - val_loss: 0.5551 - val_acc: 0.7304\n",
      "Epoch 452/1000\n",
      "537/537 [==============================] - 0s 90us/step - loss: 0.5696 - acc: 0.7058 - val_loss: 0.5512 - val_acc: 0.7217\n",
      "Epoch 453/1000\n",
      "537/537 [==============================] - 0s 98us/step - loss: 0.5789 - acc: 0.7132 - val_loss: 0.5540 - val_acc: 0.7217\n",
      "Epoch 454/1000\n",
      "537/537 [==============================] - 0s 86us/step - loss: 0.5723 - acc: 0.7169 - val_loss: 0.5487 - val_acc: 0.7391\n",
      "Epoch 455/1000\n",
      "537/537 [==============================] - 0s 80us/step - loss: 0.5586 - acc: 0.7095 - val_loss: 0.5496 - val_acc: 0.7391\n",
      "Epoch 456/1000\n",
      "537/537 [==============================] - 0s 82us/step - loss: 0.5694 - acc: 0.7039 - val_loss: 0.5529 - val_acc: 0.7217\n",
      "Epoch 457/1000\n",
      "537/537 [==============================] - 0s 98us/step - loss: 0.5919 - acc: 0.7039 - val_loss: 0.5571 - val_acc: 0.7217\n",
      "Epoch 458/1000\n",
      "537/537 [==============================] - 0s 84us/step - loss: 0.5769 - acc: 0.6983 - val_loss: 0.5594 - val_acc: 0.7217\n",
      "Epoch 459/1000\n",
      "537/537 [==============================] - 0s 84us/step - loss: 0.5960 - acc: 0.6834 - val_loss: 0.5616 - val_acc: 0.7217\n",
      "Epoch 460/1000\n",
      "537/537 [==============================] - 0s 84us/step - loss: 0.5781 - acc: 0.7039 - val_loss: 0.5641 - val_acc: 0.7217\n",
      "Epoch 461/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.5488 - acc: 0.7151 - val_loss: 0.5626 - val_acc: 0.7391\n",
      "Epoch 462/1000\n",
      "537/537 [==============================] - 0s 85us/step - loss: 0.5876 - acc: 0.7114 - val_loss: 0.5630 - val_acc: 0.7391\n",
      "Epoch 463/1000\n",
      "537/537 [==============================] - 0s 77us/step - loss: 0.5805 - acc: 0.7076 - val_loss: 0.5605 - val_acc: 0.7391\n",
      "Epoch 464/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.5677 - acc: 0.6946 - val_loss: 0.5616 - val_acc: 0.7391\n",
      "Epoch 465/1000\n",
      "537/537 [==============================] - 0s 74us/step - loss: 0.5821 - acc: 0.6965 - val_loss: 0.5668 - val_acc: 0.7217\n",
      "Epoch 466/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.5745 - acc: 0.6983 - val_loss: 0.5636 - val_acc: 0.7217\n",
      "Epoch 467/1000\n",
      "537/537 [==============================] - 0s 80us/step - loss: 0.6010 - acc: 0.6909 - val_loss: 0.5620 - val_acc: 0.7217\n",
      "Epoch 468/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.5814 - acc: 0.7132 - val_loss: 0.5598 - val_acc: 0.7304\n",
      "Epoch 469/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.5911 - acc: 0.6965 - val_loss: 0.5615 - val_acc: 0.7130\n",
      "Epoch 470/1000\n",
      "537/537 [==============================] - 0s 84us/step - loss: 0.5665 - acc: 0.7039 - val_loss: 0.5576 - val_acc: 0.7391\n",
      "Epoch 471/1000\n",
      "537/537 [==============================] - 0s 93us/step - loss: 0.5816 - acc: 0.7020 - val_loss: 0.5640 - val_acc: 0.7217\n",
      "Epoch 472/1000\n",
      "537/537 [==============================] - 0s 82us/step - loss: 0.5895 - acc: 0.6927 - val_loss: 0.5598 - val_acc: 0.7217\n",
      "Epoch 473/1000\n",
      "537/537 [==============================] - 0s 82us/step - loss: 0.5696 - acc: 0.7151 - val_loss: 0.5596 - val_acc: 0.7304\n",
      "Epoch 474/1000\n",
      "537/537 [==============================] - 0s 86us/step - loss: 0.5846 - acc: 0.7207 - val_loss: 0.5583 - val_acc: 0.7304\n",
      "Epoch 475/1000\n",
      "537/537 [==============================] - 0s 79us/step - loss: 0.5745 - acc: 0.7039 - val_loss: 0.5627 - val_acc: 0.7304\n",
      "Epoch 476/1000\n",
      "537/537 [==============================] - 0s 79us/step - loss: 0.5891 - acc: 0.7076 - val_loss: 0.5605 - val_acc: 0.7304\n",
      "Epoch 477/1000\n",
      "537/537 [==============================] - 0s 82us/step - loss: 0.5815 - acc: 0.7114 - val_loss: 0.5601 - val_acc: 0.7217\n",
      "Epoch 478/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.5641 - acc: 0.7151 - val_loss: 0.5636 - val_acc: 0.7217\n",
      "Epoch 479/1000\n",
      "537/537 [==============================] - 0s 79us/step - loss: 0.5631 - acc: 0.7039 - val_loss: 0.5629 - val_acc: 0.7391\n",
      "Epoch 480/1000\n",
      "537/537 [==============================] - 0s 79us/step - loss: 0.5859 - acc: 0.7039 - val_loss: 0.5648 - val_acc: 0.7304\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 481/1000\n",
      "537/537 [==============================] - 0s 86us/step - loss: 0.5864 - acc: 0.6946 - val_loss: 0.5604 - val_acc: 0.7217\n",
      "Epoch 482/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.5697 - acc: 0.7039 - val_loss: 0.5633 - val_acc: 0.7304\n",
      "Epoch 483/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.5699 - acc: 0.7095 - val_loss: 0.5627 - val_acc: 0.7391\n",
      "Epoch 484/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.5697 - acc: 0.7039 - val_loss: 0.5657 - val_acc: 0.7304\n",
      "Epoch 485/1000\n",
      "537/537 [==============================] - 0s 89us/step - loss: 0.5563 - acc: 0.7300 - val_loss: 0.5620 - val_acc: 0.7217\n",
      "Epoch 486/1000\n",
      "537/537 [==============================] - 0s 77us/step - loss: 0.5630 - acc: 0.7114 - val_loss: 0.5548 - val_acc: 0.7217\n",
      "Epoch 487/1000\n",
      "537/537 [==============================] - 0s 77us/step - loss: 0.5547 - acc: 0.7225 - val_loss: 0.5569 - val_acc: 0.7391\n",
      "Epoch 488/1000\n",
      "537/537 [==============================] - 0s 75us/step - loss: 0.5620 - acc: 0.7132 - val_loss: 0.5579 - val_acc: 0.7217\n",
      "Epoch 489/1000\n",
      "537/537 [==============================] - 0s 76us/step - loss: 0.5815 - acc: 0.7095 - val_loss: 0.5586 - val_acc: 0.7130\n",
      "Epoch 490/1000\n",
      "537/537 [==============================] - 0s 74us/step - loss: 0.5769 - acc: 0.6797 - val_loss: 0.5673 - val_acc: 0.7043\n",
      "Epoch 491/1000\n",
      "537/537 [==============================] - 0s 76us/step - loss: 0.5809 - acc: 0.7020 - val_loss: 0.5639 - val_acc: 0.7217\n",
      "Epoch 492/1000\n",
      "537/537 [==============================] - 0s 80us/step - loss: 0.5813 - acc: 0.6946 - val_loss: 0.5601 - val_acc: 0.7130\n",
      "Epoch 493/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.5603 - acc: 0.7076 - val_loss: 0.5642 - val_acc: 0.7304\n",
      "Epoch 494/1000\n",
      "537/537 [==============================] - 0s 75us/step - loss: 0.5761 - acc: 0.7020 - val_loss: 0.5661 - val_acc: 0.7217\n",
      "Epoch 495/1000\n",
      "537/537 [==============================] - 0s 75us/step - loss: 0.5965 - acc: 0.6946 - val_loss: 0.5690 - val_acc: 0.7304\n",
      "Epoch 496/1000\n",
      "537/537 [==============================] - 0s 76us/step - loss: 0.5767 - acc: 0.7095 - val_loss: 0.5632 - val_acc: 0.7304\n",
      "Epoch 497/1000\n",
      "537/537 [==============================] - 0s 77us/step - loss: 0.5747 - acc: 0.7020 - val_loss: 0.5671 - val_acc: 0.7304\n",
      "Epoch 498/1000\n",
      "537/537 [==============================] - 0s 82us/step - loss: 0.5875 - acc: 0.6946 - val_loss: 0.5671 - val_acc: 0.7217\n",
      "Epoch 499/1000\n",
      "537/537 [==============================] - 0s 79us/step - loss: 0.5935 - acc: 0.7076 - val_loss: 0.5762 - val_acc: 0.7304\n",
      "Epoch 500/1000\n",
      "537/537 [==============================] - 0s 80us/step - loss: 0.5839 - acc: 0.6946 - val_loss: 0.5790 - val_acc: 0.7217\n",
      "Epoch 501/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.5749 - acc: 0.7020 - val_loss: 0.5675 - val_acc: 0.7304\n",
      "Epoch 502/1000\n",
      "537/537 [==============================] - 0s 80us/step - loss: 0.5882 - acc: 0.7076 - val_loss: 0.5683 - val_acc: 0.7391\n",
      "Epoch 503/1000\n",
      "537/537 [==============================] - 0s 76us/step - loss: 0.5946 - acc: 0.6834 - val_loss: 0.5726 - val_acc: 0.7304\n",
      "Epoch 504/1000\n",
      "537/537 [==============================] - 0s 77us/step - loss: 0.5749 - acc: 0.7114 - val_loss: 0.5736 - val_acc: 0.7304\n",
      "Epoch 505/1000\n",
      "537/537 [==============================] - 0s 82us/step - loss: 0.5625 - acc: 0.7076 - val_loss: 0.5749 - val_acc: 0.7478\n",
      "Epoch 506/1000\n",
      "537/537 [==============================] - 0s 80us/step - loss: 0.5727 - acc: 0.7095 - val_loss: 0.5777 - val_acc: 0.7391\n",
      "Epoch 507/1000\n",
      "537/537 [==============================] - 0s 84us/step - loss: 0.5671 - acc: 0.7114 - val_loss: 0.5733 - val_acc: 0.7478\n",
      "Epoch 508/1000\n",
      "537/537 [==============================] - 0s 92us/step - loss: 0.5792 - acc: 0.7002 - val_loss: 0.5698 - val_acc: 0.7391\n",
      "Epoch 509/1000\n",
      "537/537 [==============================] - 0s 85us/step - loss: 0.5826 - acc: 0.7207 - val_loss: 0.5719 - val_acc: 0.7304\n",
      "Epoch 510/1000\n",
      "537/537 [==============================] - 0s 77us/step - loss: 0.5709 - acc: 0.7039 - val_loss: 0.5716 - val_acc: 0.7478\n",
      "Epoch 511/1000\n",
      "537/537 [==============================] - 0s 83us/step - loss: 0.5861 - acc: 0.6834 - val_loss: 0.5680 - val_acc: 0.7304\n",
      "Epoch 512/1000\n",
      "537/537 [==============================] - 0s 75us/step - loss: 0.5813 - acc: 0.6965 - val_loss: 0.5715 - val_acc: 0.7130\n",
      "Epoch 513/1000\n",
      "537/537 [==============================] - 0s 83us/step - loss: 0.5619 - acc: 0.7207 - val_loss: 0.5738 - val_acc: 0.7217\n",
      "Epoch 514/1000\n",
      "537/537 [==============================] - 0s 76us/step - loss: 0.5631 - acc: 0.6965 - val_loss: 0.5706 - val_acc: 0.7130\n",
      "Epoch 515/1000\n",
      "537/537 [==============================] - 0s 76us/step - loss: 0.5735 - acc: 0.7039 - val_loss: 0.5634 - val_acc: 0.7217\n",
      "Epoch 516/1000\n",
      "537/537 [==============================] - 0s 76us/step - loss: 0.5817 - acc: 0.6890 - val_loss: 0.5663 - val_acc: 0.7130\n",
      "Epoch 517/1000\n",
      "537/537 [==============================] - 0s 77us/step - loss: 0.5847 - acc: 0.7169 - val_loss: 0.5666 - val_acc: 0.7217\n",
      "Epoch 518/1000\n",
      "537/537 [==============================] - 0s 76us/step - loss: 0.5677 - acc: 0.7244 - val_loss: 0.5689 - val_acc: 0.7130\n",
      "Epoch 519/1000\n",
      "537/537 [==============================] - 0s 75us/step - loss: 0.5603 - acc: 0.7207 - val_loss: 0.5662 - val_acc: 0.7217\n",
      "Epoch 520/1000\n",
      "537/537 [==============================] - 0s 77us/step - loss: 0.5843 - acc: 0.7058 - val_loss: 0.5685 - val_acc: 0.7304\n",
      "Epoch 521/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.5777 - acc: 0.7058 - val_loss: 0.5705 - val_acc: 0.7130\n",
      "Epoch 522/1000\n",
      "537/537 [==============================] - 0s 77us/step - loss: 0.5782 - acc: 0.6983 - val_loss: 0.5657 - val_acc: 0.7304\n",
      "Epoch 523/1000\n",
      "537/537 [==============================] - 0s 77us/step - loss: 0.5661 - acc: 0.7114 - val_loss: 0.5697 - val_acc: 0.7130\n",
      "Epoch 524/1000\n",
      "537/537 [==============================] - 0s 77us/step - loss: 0.5813 - acc: 0.7095 - val_loss: 0.5699 - val_acc: 0.7304\n",
      "Epoch 525/1000\n",
      "537/537 [==============================] - 0s 84us/step - loss: 0.5813 - acc: 0.7188 - val_loss: 0.5710 - val_acc: 0.7217\n",
      "Epoch 526/1000\n",
      "537/537 [==============================] - 0s 75us/step - loss: 0.5879 - acc: 0.6946 - val_loss: 0.5723 - val_acc: 0.7304\n",
      "Epoch 527/1000\n",
      "537/537 [==============================] - 0s 79us/step - loss: 0.5772 - acc: 0.7169 - val_loss: 0.5761 - val_acc: 0.7304\n",
      "Epoch 528/1000\n",
      "537/537 [==============================] - 0s 73us/step - loss: 0.5876 - acc: 0.7076 - val_loss: 0.5714 - val_acc: 0.7217\n",
      "Epoch 529/1000\n",
      "537/537 [==============================] - 0s 74us/step - loss: 0.5909 - acc: 0.7076 - val_loss: 0.5719 - val_acc: 0.7217\n",
      "Epoch 530/1000\n",
      "537/537 [==============================] - 0s 73us/step - loss: 0.5614 - acc: 0.7095 - val_loss: 0.5709 - val_acc: 0.7043\n",
      "Epoch 531/1000\n",
      "537/537 [==============================] - 0s 73us/step - loss: 0.5738 - acc: 0.7114 - val_loss: 0.5717 - val_acc: 0.7130\n",
      "Epoch 532/1000\n",
      "537/537 [==============================] - 0s 72us/step - loss: 0.5602 - acc: 0.7095 - val_loss: 0.5698 - val_acc: 0.7130\n",
      "Epoch 533/1000\n",
      "537/537 [==============================] - 0s 99us/step - loss: 0.5689 - acc: 0.7263 - val_loss: 0.5739 - val_acc: 0.7304\n",
      "Epoch 534/1000\n",
      "537/537 [==============================] - 0s 83us/step - loss: 0.5834 - acc: 0.7076 - val_loss: 0.5769 - val_acc: 0.7217\n",
      "Epoch 535/1000\n",
      "537/537 [==============================] - 0s 149us/step - loss: 0.5643 - acc: 0.7263 - val_loss: 0.5735 - val_acc: 0.7217\n",
      "Epoch 536/1000\n",
      "537/537 [==============================] - 0s 91us/step - loss: 0.5705 - acc: 0.6909 - val_loss: 0.5781 - val_acc: 0.7043\n",
      "Epoch 537/1000\n",
      "537/537 [==============================] - 0s 86us/step - loss: 0.5609 - acc: 0.7132 - val_loss: 0.5625 - val_acc: 0.7043\n",
      "Epoch 538/1000\n",
      "537/537 [==============================] - 0s 109us/step - loss: 0.5757 - acc: 0.7169 - val_loss: 0.5578 - val_acc: 0.7043\n",
      "Epoch 539/1000\n",
      "537/537 [==============================] - 0s 81us/step - loss: 0.5685 - acc: 0.7188 - val_loss: 0.5594 - val_acc: 0.7130\n",
      "Epoch 540/1000\n",
      "537/537 [==============================] - 0s 80us/step - loss: 0.5617 - acc: 0.7095 - val_loss: 0.5571 - val_acc: 0.7304\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 541/1000\n",
      "537/537 [==============================] - 0s 81us/step - loss: 0.5650 - acc: 0.7132 - val_loss: 0.5616 - val_acc: 0.7217\n",
      "Epoch 542/1000\n",
      "537/537 [==============================] - 0s 80us/step - loss: 0.5568 - acc: 0.7169 - val_loss: 0.5600 - val_acc: 0.7217\n",
      "Epoch 543/1000\n",
      "537/537 [==============================] - 0s 83us/step - loss: 0.5895 - acc: 0.6965 - val_loss: 0.5656 - val_acc: 0.7130\n",
      "Epoch 544/1000\n",
      "537/537 [==============================] - 0s 80us/step - loss: 0.5768 - acc: 0.7058 - val_loss: 0.5704 - val_acc: 0.7217\n",
      "Epoch 545/1000\n",
      "537/537 [==============================] - 0s 80us/step - loss: 0.5625 - acc: 0.7058 - val_loss: 0.5674 - val_acc: 0.6957\n",
      "Epoch 546/1000\n",
      "537/537 [==============================] - 0s 85us/step - loss: 0.5642 - acc: 0.7300 - val_loss: 0.5641 - val_acc: 0.7391\n",
      "Epoch 547/1000\n",
      "537/537 [==============================] - 0s 83us/step - loss: 0.5606 - acc: 0.7244 - val_loss: 0.5696 - val_acc: 0.6957\n",
      "Epoch 548/1000\n",
      "537/537 [==============================] - 0s 79us/step - loss: 0.5740 - acc: 0.7169 - val_loss: 0.5430 - val_acc: 0.7043\n",
      "Epoch 549/1000\n",
      "537/537 [==============================] - 0s 81us/step - loss: 0.5580 - acc: 0.7318 - val_loss: 0.5434 - val_acc: 0.7130\n",
      "Epoch 550/1000\n",
      "537/537 [==============================] - 0s 79us/step - loss: 0.5832 - acc: 0.6909 - val_loss: 0.5503 - val_acc: 0.7217\n",
      "Epoch 551/1000\n",
      "537/537 [==============================] - 0s 81us/step - loss: 0.5962 - acc: 0.6890 - val_loss: 0.5509 - val_acc: 0.7043\n",
      "Epoch 552/1000\n",
      "537/537 [==============================] - 0s 79us/step - loss: 0.5643 - acc: 0.7207 - val_loss: 0.5513 - val_acc: 0.7304\n",
      "Epoch 553/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.5888 - acc: 0.6872 - val_loss: 0.5552 - val_acc: 0.7043\n",
      "Epoch 554/1000\n",
      "537/537 [==============================] - 0s 85us/step - loss: 0.5630 - acc: 0.7188 - val_loss: 0.5500 - val_acc: 0.7217\n",
      "Epoch 555/1000\n",
      "537/537 [==============================] - 0s 83us/step - loss: 0.5746 - acc: 0.6834 - val_loss: 0.5477 - val_acc: 0.7304\n",
      "Epoch 556/1000\n",
      "537/537 [==============================] - 0s 83us/step - loss: 0.5753 - acc: 0.7114 - val_loss: 0.5465 - val_acc: 0.7043\n",
      "Epoch 557/1000\n",
      "537/537 [==============================] - 0s 80us/step - loss: 0.5830 - acc: 0.7002 - val_loss: 0.5528 - val_acc: 0.6957\n",
      "Epoch 558/1000\n",
      "537/537 [==============================] - 0s 83us/step - loss: 0.5680 - acc: 0.7114 - val_loss: 0.5505 - val_acc: 0.7130\n",
      "Epoch 559/1000\n",
      "537/537 [==============================] - 0s 89us/step - loss: 0.5779 - acc: 0.6927 - val_loss: 0.5569 - val_acc: 0.6957\n",
      "Epoch 560/1000\n",
      "537/537 [==============================] - 0s 82us/step - loss: 0.5813 - acc: 0.7020 - val_loss: 0.5529 - val_acc: 0.7217\n",
      "Epoch 561/1000\n",
      "537/537 [==============================] - 0s 81us/step - loss: 0.5586 - acc: 0.7225 - val_loss: 0.5590 - val_acc: 0.7217\n",
      "Epoch 562/1000\n",
      "537/537 [==============================] - 0s 82us/step - loss: 0.5598 - acc: 0.6983 - val_loss: 0.5546 - val_acc: 0.7130\n",
      "Epoch 563/1000\n",
      "537/537 [==============================] - 0s 87us/step - loss: 0.5607 - acc: 0.7263 - val_loss: 0.5543 - val_acc: 0.7391\n",
      "Epoch 564/1000\n",
      "537/537 [==============================] - 0s 82us/step - loss: 0.5661 - acc: 0.7188 - val_loss: 0.5517 - val_acc: 0.7130\n",
      "Epoch 565/1000\n",
      "537/537 [==============================] - 0s 84us/step - loss: 0.5651 - acc: 0.7020 - val_loss: 0.5479 - val_acc: 0.7043\n",
      "Epoch 566/1000\n",
      "537/537 [==============================] - 0s 75us/step - loss: 0.5580 - acc: 0.7076 - val_loss: 0.5517 - val_acc: 0.7043\n",
      "Epoch 567/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.5841 - acc: 0.6983 - val_loss: 0.5552 - val_acc: 0.7130\n",
      "Epoch 568/1000\n",
      "537/537 [==============================] - 0s 77us/step - loss: 0.5740 - acc: 0.7076 - val_loss: 0.5604 - val_acc: 0.7043\n",
      "Epoch 569/1000\n",
      "537/537 [==============================] - 0s 76us/step - loss: 0.5524 - acc: 0.7169 - val_loss: 0.5616 - val_acc: 0.7130\n",
      "Epoch 570/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.5726 - acc: 0.7002 - val_loss: 0.5576 - val_acc: 0.6870\n",
      "Epoch 571/1000\n",
      "537/537 [==============================] - 0s 74us/step - loss: 0.5579 - acc: 0.7169 - val_loss: 0.5571 - val_acc: 0.7217\n",
      "Epoch 572/1000\n",
      "537/537 [==============================] - 0s 74us/step - loss: 0.5612 - acc: 0.7114 - val_loss: 0.5600 - val_acc: 0.7043\n",
      "Epoch 573/1000\n",
      "537/537 [==============================] - 0s 77us/step - loss: 0.5714 - acc: 0.7114 - val_loss: 0.5564 - val_acc: 0.7043\n",
      "Epoch 574/1000\n",
      "537/537 [==============================] - 0s 75us/step - loss: 0.5603 - acc: 0.7207 - val_loss: 0.5551 - val_acc: 0.7130\n",
      "Epoch 575/1000\n",
      "537/537 [==============================] - 0s 75us/step - loss: 0.5695 - acc: 0.7020 - val_loss: 0.5495 - val_acc: 0.7478\n",
      "Epoch 576/1000\n",
      "537/537 [==============================] - 0s 75us/step - loss: 0.5691 - acc: 0.7207 - val_loss: 0.5571 - val_acc: 0.7217\n",
      "Epoch 577/1000\n",
      "537/537 [==============================] - 0s 75us/step - loss: 0.5735 - acc: 0.7039 - val_loss: 0.5548 - val_acc: 0.7304\n",
      "Epoch 578/1000\n",
      "537/537 [==============================] - 0s 76us/step - loss: 0.5583 - acc: 0.7095 - val_loss: 0.5536 - val_acc: 0.7217\n",
      "Epoch 579/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.5715 - acc: 0.7151 - val_loss: 0.5510 - val_acc: 0.7217\n",
      "Epoch 580/1000\n",
      "537/537 [==============================] - 0s 76us/step - loss: 0.5630 - acc: 0.6890 - val_loss: 0.5552 - val_acc: 0.7043\n",
      "Epoch 581/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.5814 - acc: 0.7002 - val_loss: 0.5537 - val_acc: 0.7043\n",
      "Epoch 582/1000\n",
      "537/537 [==============================] - 0s 77us/step - loss: 0.5675 - acc: 0.7132 - val_loss: 0.5586 - val_acc: 0.7130\n",
      "Epoch 583/1000\n",
      "537/537 [==============================] - 0s 85us/step - loss: 0.5597 - acc: 0.7207 - val_loss: 0.5573 - val_acc: 0.7217\n",
      "Epoch 584/1000\n",
      "537/537 [==============================] - 0s 77us/step - loss: 0.5596 - acc: 0.7039 - val_loss: 0.5609 - val_acc: 0.7304\n",
      "Epoch 585/1000\n",
      "537/537 [==============================] - 0s 74us/step - loss: 0.6020 - acc: 0.6890 - val_loss: 0.5657 - val_acc: 0.7043\n",
      "Epoch 586/1000\n",
      "537/537 [==============================] - 0s 74us/step - loss: 0.5871 - acc: 0.6983 - val_loss: 0.5632 - val_acc: 0.7130\n",
      "Epoch 587/1000\n",
      "537/537 [==============================] - 0s 80us/step - loss: 0.5619 - acc: 0.7169 - val_loss: 0.5604 - val_acc: 0.7130\n",
      "Epoch 588/1000\n",
      "537/537 [==============================] - 0s 80us/step - loss: 0.5664 - acc: 0.7058 - val_loss: 0.5602 - val_acc: 0.7304\n",
      "Epoch 589/1000\n",
      "537/537 [==============================] - 0s 81us/step - loss: 0.5678 - acc: 0.7151 - val_loss: 0.5592 - val_acc: 0.7130\n",
      "Epoch 590/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.5704 - acc: 0.7244 - val_loss: 0.5610 - val_acc: 0.7130\n",
      "Epoch 591/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.5786 - acc: 0.7132 - val_loss: 0.5570 - val_acc: 0.7217\n",
      "Epoch 592/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.5593 - acc: 0.7225 - val_loss: 0.5566 - val_acc: 0.7217\n",
      "Epoch 593/1000\n",
      "537/537 [==============================] - 0s 81us/step - loss: 0.5628 - acc: 0.7169 - val_loss: 0.5534 - val_acc: 0.7217\n",
      "Epoch 594/1000\n",
      "537/537 [==============================] - 0s 79us/step - loss: 0.5775 - acc: 0.7151 - val_loss: 0.5578 - val_acc: 0.7217\n",
      "Epoch 595/1000\n",
      "537/537 [==============================] - 0s 83us/step - loss: 0.5770 - acc: 0.6983 - val_loss: 0.5595 - val_acc: 0.7391\n",
      "Epoch 596/1000\n",
      "537/537 [==============================] - 0s 80us/step - loss: 0.5957 - acc: 0.6983 - val_loss: 0.5632 - val_acc: 0.7391\n",
      "Epoch 597/1000\n",
      "537/537 [==============================] - 0s 86us/step - loss: 0.5732 - acc: 0.7020 - val_loss: 0.5623 - val_acc: 0.7304\n",
      "Epoch 598/1000\n",
      "537/537 [==============================] - 0s 85us/step - loss: 0.5517 - acc: 0.7169 - val_loss: 0.5595 - val_acc: 0.7304\n",
      "Epoch 599/1000\n",
      "537/537 [==============================] - 0s 81us/step - loss: 0.5815 - acc: 0.7114 - val_loss: 0.5654 - val_acc: 0.7391\n",
      "Epoch 600/1000\n",
      "537/537 [==============================] - 0s 86us/step - loss: 0.5770 - acc: 0.6927 - val_loss: 0.5694 - val_acc: 0.7043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 601/1000\n",
      "537/537 [==============================] - 0s 97us/step - loss: 0.5528 - acc: 0.7188 - val_loss: 0.5635 - val_acc: 0.7304\n",
      "Epoch 602/1000\n",
      "537/537 [==============================] - 0s 89us/step - loss: 0.5625 - acc: 0.7169 - val_loss: 0.5649 - val_acc: 0.7304\n",
      "Epoch 603/1000\n",
      "537/537 [==============================] - 0s 89us/step - loss: 0.5703 - acc: 0.7095 - val_loss: 0.5705 - val_acc: 0.7130\n",
      "Epoch 604/1000\n",
      "537/537 [==============================] - 0s 84us/step - loss: 0.5653 - acc: 0.7114 - val_loss: 0.5696 - val_acc: 0.7043\n",
      "Epoch 605/1000\n",
      "537/537 [==============================] - 0s 90us/step - loss: 0.5697 - acc: 0.7132 - val_loss: 0.5594 - val_acc: 0.7391\n",
      "Epoch 606/1000\n",
      "537/537 [==============================] - 0s 82us/step - loss: 0.5792 - acc: 0.7076 - val_loss: 0.5656 - val_acc: 0.7391\n",
      "Epoch 607/1000\n",
      "537/537 [==============================] - 0s 80us/step - loss: 0.5781 - acc: 0.7039 - val_loss: 0.5644 - val_acc: 0.7304\n",
      "Epoch 608/1000\n",
      "537/537 [==============================] - 0s 77us/step - loss: 0.5773 - acc: 0.7076 - val_loss: 0.5673 - val_acc: 0.7304\n",
      "Epoch 609/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.5777 - acc: 0.7020 - val_loss: 0.5652 - val_acc: 0.7043\n",
      "Epoch 610/1000\n",
      "537/537 [==============================] - 0s 82us/step - loss: 0.5815 - acc: 0.6890 - val_loss: 0.5655 - val_acc: 0.6957\n",
      "Epoch 611/1000\n",
      "537/537 [==============================] - 0s 80us/step - loss: 0.5895 - acc: 0.7020 - val_loss: 0.5669 - val_acc: 0.7043\n",
      "Epoch 612/1000\n",
      "537/537 [==============================] - 0s 81us/step - loss: 0.5762 - acc: 0.7076 - val_loss: 0.5706 - val_acc: 0.7217\n",
      "Epoch 613/1000\n",
      "537/537 [==============================] - 0s 80us/step - loss: 0.5772 - acc: 0.7020 - val_loss: 0.5656 - val_acc: 0.7043\n",
      "Epoch 614/1000\n",
      "537/537 [==============================] - 0s 82us/step - loss: 0.5704 - acc: 0.7151 - val_loss: 0.5618 - val_acc: 0.7217\n",
      "Epoch 615/1000\n",
      "537/537 [==============================] - 0s 86us/step - loss: 0.5681 - acc: 0.6965 - val_loss: 0.5640 - val_acc: 0.7130\n",
      "Epoch 616/1000\n",
      "537/537 [==============================] - 0s 84us/step - loss: 0.5746 - acc: 0.7076 - val_loss: 0.5714 - val_acc: 0.7304\n",
      "Epoch 617/1000\n",
      "537/537 [==============================] - 0s 80us/step - loss: 0.5965 - acc: 0.7002 - val_loss: 0.5778 - val_acc: 0.6957\n",
      "Epoch 618/1000\n",
      "537/537 [==============================] - 0s 93us/step - loss: 0.5602 - acc: 0.7114 - val_loss: 0.5710 - val_acc: 0.7217\n",
      "Epoch 619/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.5670 - acc: 0.7095 - val_loss: 0.5726 - val_acc: 0.7043\n",
      "Epoch 620/1000\n",
      "537/537 [==============================] - 0s 84us/step - loss: 0.5750 - acc: 0.7151 - val_loss: 0.5752 - val_acc: 0.7043\n",
      "Epoch 621/1000\n",
      "537/537 [==============================] - 0s 83us/step - loss: 0.5634 - acc: 0.7225 - val_loss: 0.5694 - val_acc: 0.7391\n",
      "Epoch 622/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.5683 - acc: 0.7095 - val_loss: 0.5476 - val_acc: 0.7304\n",
      "Epoch 623/1000\n",
      "537/537 [==============================] - 0s 86us/step - loss: 0.5789 - acc: 0.6927 - val_loss: 0.5478 - val_acc: 0.7043\n",
      "Epoch 624/1000\n",
      "537/537 [==============================] - 0s 79us/step - loss: 0.5751 - acc: 0.7076 - val_loss: 0.5515 - val_acc: 0.6957\n",
      "Epoch 625/1000\n",
      "537/537 [==============================] - 0s 80us/step - loss: 0.5818 - acc: 0.7058 - val_loss: 0.5554 - val_acc: 0.7304\n",
      "Epoch 626/1000\n",
      "537/537 [==============================] - 0s 76us/step - loss: 0.5719 - acc: 0.6909 - val_loss: 0.5558 - val_acc: 0.7217\n",
      "Epoch 627/1000\n",
      "537/537 [==============================] - 0s 79us/step - loss: 0.5755 - acc: 0.7095 - val_loss: 0.5552 - val_acc: 0.7391\n",
      "Epoch 628/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.5734 - acc: 0.7039 - val_loss: 0.5586 - val_acc: 0.7043\n",
      "Epoch 629/1000\n",
      "537/537 [==============================] - 0s 81us/step - loss: 0.5654 - acc: 0.7207 - val_loss: 0.5567 - val_acc: 0.7130\n",
      "Epoch 630/1000\n",
      "537/537 [==============================] - 0s 76us/step - loss: 0.5649 - acc: 0.7095 - val_loss: 0.5537 - val_acc: 0.7391\n",
      "Epoch 631/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.5797 - acc: 0.7020 - val_loss: 0.5589 - val_acc: 0.7130\n",
      "Epoch 632/1000\n",
      "537/537 [==============================] - 0s 76us/step - loss: 0.5597 - acc: 0.7207 - val_loss: 0.5593 - val_acc: 0.7130\n",
      "Epoch 633/1000\n",
      "537/537 [==============================] - 0s 83us/step - loss: 0.5654 - acc: 0.7132 - val_loss: 0.5627 - val_acc: 0.7130\n",
      "Epoch 634/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.5617 - acc: 0.7263 - val_loss: 0.5593 - val_acc: 0.7130\n",
      "Epoch 635/1000\n",
      "537/537 [==============================] - 0s 84us/step - loss: 0.5638 - acc: 0.7281 - val_loss: 0.5605 - val_acc: 0.7043\n",
      "Epoch 636/1000\n",
      "537/537 [==============================] - 0s 76us/step - loss: 0.5604 - acc: 0.7188 - val_loss: 0.5566 - val_acc: 0.7217\n",
      "Epoch 637/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.5767 - acc: 0.7002 - val_loss: 0.5539 - val_acc: 0.7043\n",
      "Epoch 638/1000\n",
      "537/537 [==============================] - 0s 81us/step - loss: 0.5515 - acc: 0.7095 - val_loss: 0.5537 - val_acc: 0.7304\n",
      "Epoch 639/1000\n",
      "537/537 [==============================] - 0s 79us/step - loss: 0.5719 - acc: 0.7076 - val_loss: 0.5547 - val_acc: 0.7304\n",
      "Epoch 640/1000\n",
      "537/537 [==============================] - 0s 86us/step - loss: 0.5664 - acc: 0.7225 - val_loss: 0.5611 - val_acc: 0.7304\n",
      "Epoch 641/1000\n",
      "537/537 [==============================] - 0s 84us/step - loss: 0.5641 - acc: 0.7039 - val_loss: 0.5607 - val_acc: 0.7130\n",
      "Epoch 642/1000\n",
      "537/537 [==============================] - 0s 82us/step - loss: 0.5437 - acc: 0.7244 - val_loss: 0.5585 - val_acc: 0.7130\n",
      "Epoch 643/1000\n",
      "537/537 [==============================] - 0s 85us/step - loss: 0.5536 - acc: 0.7207 - val_loss: 0.5632 - val_acc: 0.7043\n",
      "Epoch 644/1000\n",
      "537/537 [==============================] - 0s 80us/step - loss: 0.5669 - acc: 0.7020 - val_loss: 0.5621 - val_acc: 0.7130\n",
      "Epoch 645/1000\n",
      "537/537 [==============================] - 0s 82us/step - loss: 0.5559 - acc: 0.7169 - val_loss: 0.5637 - val_acc: 0.7217\n",
      "Epoch 646/1000\n",
      "537/537 [==============================] - 0s 93us/step - loss: 0.5760 - acc: 0.7076 - val_loss: 0.5658 - val_acc: 0.7217\n",
      "Epoch 647/1000\n",
      "537/537 [==============================] - 0s 83us/step - loss: 0.5511 - acc: 0.7207 - val_loss: 0.5620 - val_acc: 0.7130\n",
      "Epoch 648/1000\n",
      "537/537 [==============================] - 0s 81us/step - loss: 0.5470 - acc: 0.7281 - val_loss: 0.5614 - val_acc: 0.7217\n",
      "Epoch 649/1000\n",
      "537/537 [==============================] - 0s 81us/step - loss: 0.5463 - acc: 0.7281 - val_loss: 0.5627 - val_acc: 0.7130\n",
      "Epoch 650/1000\n",
      "537/537 [==============================] - 0s 98us/step - loss: 0.5891 - acc: 0.6946 - val_loss: 0.5685 - val_acc: 0.7217\n",
      "Epoch 651/1000\n",
      "537/537 [==============================] - 0s 82us/step - loss: 0.5822 - acc: 0.6965 - val_loss: 0.5763 - val_acc: 0.7217\n",
      "Epoch 652/1000\n",
      "537/537 [==============================] - 0s 118us/step - loss: 0.5723 - acc: 0.6983 - val_loss: 0.5724 - val_acc: 0.7217\n",
      "Epoch 653/1000\n",
      "537/537 [==============================] - 0s 84us/step - loss: 0.5541 - acc: 0.7263 - val_loss: 0.5668 - val_acc: 0.7217\n",
      "Epoch 654/1000\n",
      "537/537 [==============================] - 0s 80us/step - loss: 0.5744 - acc: 0.7076 - val_loss: 0.5745 - val_acc: 0.7043\n",
      "Epoch 655/1000\n",
      "537/537 [==============================] - 0s 77us/step - loss: 0.5783 - acc: 0.6927 - val_loss: 0.5786 - val_acc: 0.7043\n",
      "Epoch 656/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.5541 - acc: 0.7374 - val_loss: 0.5794 - val_acc: 0.7217\n",
      "Epoch 657/1000\n",
      "537/537 [==============================] - 0s 83us/step - loss: 0.5586 - acc: 0.7095 - val_loss: 0.5707 - val_acc: 0.7130\n",
      "Epoch 658/1000\n",
      "537/537 [==============================] - 0s 86us/step - loss: 0.5844 - acc: 0.6965 - val_loss: 0.5736 - val_acc: 0.7304\n",
      "Epoch 659/1000\n",
      "537/537 [==============================] - 0s 80us/step - loss: 0.5624 - acc: 0.7225 - val_loss: 0.5726 - val_acc: 0.7304\n",
      "Epoch 660/1000\n",
      "537/537 [==============================] - 0s 83us/step - loss: 0.5801 - acc: 0.7020 - val_loss: 0.5740 - val_acc: 0.7304\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 661/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.5577 - acc: 0.7188 - val_loss: 0.5774 - val_acc: 0.7304\n",
      "Epoch 662/1000\n",
      "537/537 [==============================] - 0s 75us/step - loss: 0.5530 - acc: 0.7393 - val_loss: 0.5722 - val_acc: 0.7391\n",
      "Epoch 663/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.5666 - acc: 0.7132 - val_loss: 0.5738 - val_acc: 0.7304\n",
      "Epoch 664/1000\n",
      "537/537 [==============================] - 0s 79us/step - loss: 0.5801 - acc: 0.7095 - val_loss: 0.5881 - val_acc: 0.7130\n",
      "Epoch 665/1000\n",
      "537/537 [==============================] - 0s 79us/step - loss: 0.5738 - acc: 0.7058 - val_loss: 0.5801 - val_acc: 0.7043\n",
      "Epoch 666/1000\n",
      "537/537 [==============================] - 0s 75us/step - loss: 0.5735 - acc: 0.7132 - val_loss: 0.5694 - val_acc: 0.7130\n",
      "Epoch 667/1000\n",
      "537/537 [==============================] - 0s 80us/step - loss: 0.5449 - acc: 0.7412 - val_loss: 0.5483 - val_acc: 0.7391\n",
      "Epoch 668/1000\n",
      "537/537 [==============================] - 0s 80us/step - loss: 0.5662 - acc: 0.7076 - val_loss: 0.5436 - val_acc: 0.7304\n",
      "Epoch 669/1000\n",
      "537/537 [==============================] - 0s 79us/step - loss: 0.5488 - acc: 0.7300 - val_loss: 0.5424 - val_acc: 0.7391\n",
      "Epoch 670/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.5707 - acc: 0.7058 - val_loss: 0.5456 - val_acc: 0.7043\n",
      "Epoch 671/1000\n",
      "537/537 [==============================] - 0s 97us/step - loss: 0.5772 - acc: 0.7225 - val_loss: 0.5563 - val_acc: 0.7304\n",
      "Epoch 672/1000\n",
      "537/537 [==============================] - 0s 87us/step - loss: 0.5779 - acc: 0.7058 - val_loss: 0.5535 - val_acc: 0.7304\n",
      "Epoch 673/1000\n",
      "537/537 [==============================] - 0s 81us/step - loss: 0.5498 - acc: 0.7244 - val_loss: 0.5465 - val_acc: 0.7217\n",
      "Epoch 674/1000\n",
      "537/537 [==============================] - 0s 77us/step - loss: 0.5635 - acc: 0.7151 - val_loss: 0.5549 - val_acc: 0.7304\n",
      "Epoch 675/1000\n",
      "537/537 [==============================] - 0s 81us/step - loss: 0.5928 - acc: 0.6983 - val_loss: 0.5553 - val_acc: 0.7130\n",
      "Epoch 676/1000\n",
      "537/537 [==============================] - 0s 86us/step - loss: 0.5863 - acc: 0.7132 - val_loss: 0.5533 - val_acc: 0.7130\n",
      "Epoch 677/1000\n",
      "537/537 [==============================] - 0s 84us/step - loss: 0.5804 - acc: 0.6965 - val_loss: 0.5504 - val_acc: 0.7304\n",
      "Epoch 678/1000\n",
      "537/537 [==============================] - 0s 87us/step - loss: 0.5686 - acc: 0.6965 - val_loss: 0.5516 - val_acc: 0.7304\n",
      "Epoch 679/1000\n",
      "537/537 [==============================] - 0s 83us/step - loss: 0.5655 - acc: 0.7151 - val_loss: 0.5551 - val_acc: 0.7304\n",
      "Epoch 680/1000\n",
      "537/537 [==============================] - 0s 83us/step - loss: 0.5652 - acc: 0.7169 - val_loss: 0.5600 - val_acc: 0.7130\n",
      "Epoch 681/1000\n",
      "537/537 [==============================] - 0s 77us/step - loss: 0.5617 - acc: 0.7225 - val_loss: 0.5574 - val_acc: 0.7304\n",
      "Epoch 682/1000\n",
      "537/537 [==============================] - 0s 75us/step - loss: 0.5663 - acc: 0.7151 - val_loss: 0.5539 - val_acc: 0.7391\n",
      "Epoch 683/1000\n",
      "537/537 [==============================] - 0s 79us/step - loss: 0.5524 - acc: 0.7263 - val_loss: 0.5512 - val_acc: 0.7217\n",
      "Epoch 684/1000\n",
      "537/537 [==============================] - 0s 79us/step - loss: 0.5608 - acc: 0.7393 - val_loss: 0.5552 - val_acc: 0.7391\n",
      "Epoch 685/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.5661 - acc: 0.7207 - val_loss: 0.5570 - val_acc: 0.7304\n",
      "Epoch 686/1000\n",
      "537/537 [==============================] - 0s 76us/step - loss: 0.5762 - acc: 0.7039 - val_loss: 0.5560 - val_acc: 0.7130\n",
      "Epoch 687/1000\n",
      "537/537 [==============================] - 0s 86us/step - loss: 0.5722 - acc: 0.7076 - val_loss: 0.5606 - val_acc: 0.7217\n",
      "Epoch 688/1000\n",
      "537/537 [==============================] - 0s 80us/step - loss: 0.5820 - acc: 0.6946 - val_loss: 0.5626 - val_acc: 0.7130\n",
      "Epoch 689/1000\n",
      "537/537 [==============================] - 0s 76us/step - loss: 0.5961 - acc: 0.7076 - val_loss: 0.5641 - val_acc: 0.7391\n",
      "Epoch 690/1000\n",
      "537/537 [==============================] - 0s 77us/step - loss: 0.5403 - acc: 0.7244 - val_loss: 0.5632 - val_acc: 0.7304\n",
      "Epoch 691/1000\n",
      "537/537 [==============================] - 0s 84us/step - loss: 0.5794 - acc: 0.7002 - val_loss: 0.5619 - val_acc: 0.7304\n",
      "Epoch 692/1000\n",
      "537/537 [==============================] - 0s 77us/step - loss: 0.5589 - acc: 0.7263 - val_loss: 0.5619 - val_acc: 0.7217\n",
      "Epoch 693/1000\n",
      "537/537 [==============================] - 0s 87us/step - loss: 0.5411 - acc: 0.7263 - val_loss: 0.5597 - val_acc: 0.7391\n",
      "Epoch 694/1000\n",
      "537/537 [==============================] - 0s 74us/step - loss: 0.5684 - acc: 0.6965 - val_loss: 0.5635 - val_acc: 0.7130\n",
      "Epoch 695/1000\n",
      "537/537 [==============================] - 0s 80us/step - loss: 0.5717 - acc: 0.7263 - val_loss: 0.5617 - val_acc: 0.7304\n",
      "Epoch 696/1000\n",
      "537/537 [==============================] - 0s 77us/step - loss: 0.5510 - acc: 0.7132 - val_loss: 0.5604 - val_acc: 0.7217\n",
      "Epoch 697/1000\n",
      "537/537 [==============================] - 0s 76us/step - loss: 0.5594 - acc: 0.7169 - val_loss: 0.5604 - val_acc: 0.7217\n",
      "Epoch 698/1000\n",
      "537/537 [==============================] - 0s 75us/step - loss: 0.5723 - acc: 0.7244 - val_loss: 0.5589 - val_acc: 0.7217\n",
      "Epoch 699/1000\n",
      "537/537 [==============================] - 0s 74us/step - loss: 0.5487 - acc: 0.7039 - val_loss: 0.5629 - val_acc: 0.7304\n",
      "Epoch 700/1000\n",
      "537/537 [==============================] - 0s 76us/step - loss: 0.5314 - acc: 0.7337 - val_loss: 0.5606 - val_acc: 0.7130\n",
      "Epoch 701/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.5672 - acc: 0.7020 - val_loss: 0.5673 - val_acc: 0.7217\n",
      "Epoch 702/1000\n",
      "537/537 [==============================] - 0s 81us/step - loss: 0.5729 - acc: 0.7095 - val_loss: 0.5655 - val_acc: 0.7304\n",
      "Epoch 703/1000\n",
      "537/537 [==============================] - 0s 81us/step - loss: 0.5765 - acc: 0.6965 - val_loss: 0.5717 - val_acc: 0.7304\n",
      "Epoch 704/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.5645 - acc: 0.7076 - val_loss: 0.5712 - val_acc: 0.7304\n",
      "Epoch 705/1000\n",
      "537/537 [==============================] - 0s 76us/step - loss: 0.5718 - acc: 0.7076 - val_loss: 0.5722 - val_acc: 0.7217\n",
      "Epoch 706/1000\n",
      "537/537 [==============================] - 0s 85us/step - loss: 0.5376 - acc: 0.7263 - val_loss: 0.5721 - val_acc: 0.7478\n",
      "Epoch 707/1000\n",
      "537/537 [==============================] - 0s 84us/step - loss: 0.5725 - acc: 0.6965 - val_loss: 0.5751 - val_acc: 0.7217\n",
      "Epoch 708/1000\n",
      "537/537 [==============================] - 0s 84us/step - loss: 0.5742 - acc: 0.7076 - val_loss: 0.5486 - val_acc: 0.7304\n",
      "Epoch 709/1000\n",
      "537/537 [==============================] - 0s 75us/step - loss: 0.5700 - acc: 0.7169 - val_loss: 0.5453 - val_acc: 0.7217\n",
      "Epoch 710/1000\n",
      "537/537 [==============================] - 0s 87us/step - loss: 0.5547 - acc: 0.7281 - val_loss: 0.5434 - val_acc: 0.7217\n",
      "Epoch 711/1000\n",
      "537/537 [==============================] - 0s 80us/step - loss: 0.5624 - acc: 0.7207 - val_loss: 0.5439 - val_acc: 0.7217\n",
      "Epoch 712/1000\n",
      "537/537 [==============================] - 0s 88us/step - loss: 0.5702 - acc: 0.7132 - val_loss: 0.5504 - val_acc: 0.7304\n",
      "Epoch 713/1000\n",
      "537/537 [==============================] - 0s 79us/step - loss: 0.5709 - acc: 0.7151 - val_loss: 0.5540 - val_acc: 0.7391\n",
      "Epoch 714/1000\n",
      "537/537 [==============================] - 0s 86us/step - loss: 0.5598 - acc: 0.7114 - val_loss: 0.5472 - val_acc: 0.7304\n",
      "Epoch 715/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.5800 - acc: 0.7095 - val_loss: 0.5573 - val_acc: 0.7217\n",
      "Epoch 716/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.5583 - acc: 0.7151 - val_loss: 0.5560 - val_acc: 0.7304\n",
      "Epoch 717/1000\n",
      "537/537 [==============================] - 0s 80us/step - loss: 0.5746 - acc: 0.7151 - val_loss: 0.5510 - val_acc: 0.7130\n",
      "Epoch 718/1000\n",
      "537/537 [==============================] - 0s 81us/step - loss: 0.5534 - acc: 0.7263 - val_loss: 0.5528 - val_acc: 0.7130\n",
      "Epoch 719/1000\n",
      "537/537 [==============================] - 0s 81us/step - loss: 0.5863 - acc: 0.7058 - val_loss: 0.5482 - val_acc: 0.7217\n",
      "Epoch 720/1000\n",
      "537/537 [==============================] - 0s 75us/step - loss: 0.5485 - acc: 0.7207 - val_loss: 0.5485 - val_acc: 0.7043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 721/1000\n",
      "537/537 [==============================] - 0s 72us/step - loss: 0.5578 - acc: 0.7188 - val_loss: 0.5508 - val_acc: 0.7217\n",
      "Epoch 722/1000\n",
      "537/537 [==============================] - 0s 77us/step - loss: 0.5493 - acc: 0.7356 - val_loss: 0.5533 - val_acc: 0.7304\n",
      "Epoch 723/1000\n",
      "537/537 [==============================] - 0s 77us/step - loss: 0.5583 - acc: 0.7207 - val_loss: 0.5512 - val_acc: 0.7217\n",
      "Epoch 724/1000\n",
      "537/537 [==============================] - 0s 76us/step - loss: 0.5630 - acc: 0.7058 - val_loss: 0.5544 - val_acc: 0.6957\n",
      "Epoch 725/1000\n",
      "537/537 [==============================] - 0s 76us/step - loss: 0.5686 - acc: 0.7002 - val_loss: 0.5593 - val_acc: 0.7130\n",
      "Epoch 726/1000\n",
      "537/537 [==============================] - 0s 82us/step - loss: 0.5542 - acc: 0.7263 - val_loss: 0.5510 - val_acc: 0.7391\n",
      "Epoch 727/1000\n",
      "537/537 [==============================] - 0s 76us/step - loss: 0.5463 - acc: 0.7337 - val_loss: 0.5534 - val_acc: 0.7130\n",
      "Epoch 728/1000\n",
      "537/537 [==============================] - 0s 81us/step - loss: 0.5646 - acc: 0.7207 - val_loss: 0.5632 - val_acc: 0.7217\n",
      "Epoch 729/1000\n",
      "537/537 [==============================] - 0s 81us/step - loss: 0.5704 - acc: 0.7263 - val_loss: 0.5695 - val_acc: 0.7130\n",
      "Epoch 730/1000\n",
      "537/537 [==============================] - 0s 77us/step - loss: 0.5616 - acc: 0.7151 - val_loss: 0.5628 - val_acc: 0.7217\n",
      "Epoch 731/1000\n",
      "537/537 [==============================] - 0s 75us/step - loss: 0.5221 - acc: 0.7393 - val_loss: 0.5605 - val_acc: 0.7217\n",
      "Epoch 732/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.5815 - acc: 0.7039 - val_loss: 0.5604 - val_acc: 0.7130\n",
      "Epoch 733/1000\n",
      "537/537 [==============================] - 0s 81us/step - loss: 0.5467 - acc: 0.7225 - val_loss: 0.5609 - val_acc: 0.7217\n",
      "Epoch 734/1000\n",
      "537/537 [==============================] - 0s 80us/step - loss: 0.5635 - acc: 0.7263 - val_loss: 0.5636 - val_acc: 0.7304\n",
      "Epoch 735/1000\n",
      "537/537 [==============================] - 0s 81us/step - loss: 0.5395 - acc: 0.7263 - val_loss: 0.5611 - val_acc: 0.7130\n",
      "Epoch 736/1000\n",
      "537/537 [==============================] - 0s 77us/step - loss: 0.5721 - acc: 0.7151 - val_loss: 0.5596 - val_acc: 0.7304\n",
      "Epoch 737/1000\n",
      "537/537 [==============================] - 0s 87us/step - loss: 0.5711 - acc: 0.7020 - val_loss: 0.5615 - val_acc: 0.7043\n",
      "Epoch 738/1000\n",
      "537/537 [==============================] - 0s 80us/step - loss: 0.5567 - acc: 0.7225 - val_loss: 0.5630 - val_acc: 0.7130\n",
      "Epoch 739/1000\n",
      "537/537 [==============================] - 0s 77us/step - loss: 0.5614 - acc: 0.7318 - val_loss: 0.5616 - val_acc: 0.7130\n",
      "Epoch 740/1000\n",
      "537/537 [==============================] - 0s 76us/step - loss: 0.5724 - acc: 0.7318 - val_loss: 0.5659 - val_acc: 0.7217\n",
      "Epoch 741/1000\n",
      "537/537 [==============================] - 0s 84us/step - loss: 0.5763 - acc: 0.7039 - val_loss: 0.5729 - val_acc: 0.7043\n",
      "Epoch 742/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.5574 - acc: 0.7151 - val_loss: 0.5800 - val_acc: 0.7304\n",
      "Epoch 743/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.5463 - acc: 0.7244 - val_loss: 0.5796 - val_acc: 0.7130\n",
      "Epoch 744/1000\n",
      "537/537 [==============================] - 0s 79us/step - loss: 0.5547 - acc: 0.7281 - val_loss: 0.5771 - val_acc: 0.7217\n",
      "Epoch 745/1000\n",
      "537/537 [==============================] - 0s 80us/step - loss: 0.5572 - acc: 0.7188 - val_loss: 0.5772 - val_acc: 0.7130\n",
      "Epoch 746/1000\n",
      "537/537 [==============================] - 0s 80us/step - loss: 0.5983 - acc: 0.6909 - val_loss: 0.5780 - val_acc: 0.7043\n",
      "Epoch 747/1000\n",
      "537/537 [==============================] - 0s 81us/step - loss: 0.5420 - acc: 0.7393 - val_loss: 0.5747 - val_acc: 0.7304\n",
      "Epoch 748/1000\n",
      "537/537 [==============================] - 0s 80us/step - loss: 0.5618 - acc: 0.7318 - val_loss: 0.5759 - val_acc: 0.7130\n",
      "Epoch 749/1000\n",
      "537/537 [==============================] - 0s 92us/step - loss: 0.5481 - acc: 0.7244 - val_loss: 0.5779 - val_acc: 0.7130\n",
      "Epoch 750/1000\n",
      "537/537 [==============================] - 0s 77us/step - loss: 0.5637 - acc: 0.7076 - val_loss: 0.5759 - val_acc: 0.7217\n",
      "Epoch 751/1000\n",
      "537/537 [==============================] - 0s 79us/step - loss: 0.5576 - acc: 0.7281 - val_loss: 0.5708 - val_acc: 0.7217\n",
      "Epoch 752/1000\n",
      "537/537 [==============================] - 0s 85us/step - loss: 0.5269 - acc: 0.7393 - val_loss: 0.5733 - val_acc: 0.7043\n",
      "Epoch 753/1000\n",
      "537/537 [==============================] - 0s 81us/step - loss: 0.5651 - acc: 0.7263 - val_loss: 0.5796 - val_acc: 0.7217\n",
      "Epoch 754/1000\n",
      "537/537 [==============================] - 0s 79us/step - loss: 0.5625 - acc: 0.7114 - val_loss: 0.5823 - val_acc: 0.7217\n",
      "Epoch 755/1000\n",
      "537/537 [==============================] - 0s 74us/step - loss: 0.5734 - acc: 0.7132 - val_loss: 0.5495 - val_acc: 0.7217\n",
      "Epoch 756/1000\n",
      "537/537 [==============================] - 0s 79us/step - loss: 0.5675 - acc: 0.7039 - val_loss: 0.5578 - val_acc: 0.7391\n",
      "Epoch 757/1000\n",
      "537/537 [==============================] - 0s 77us/step - loss: 0.5774 - acc: 0.6927 - val_loss: 0.5613 - val_acc: 0.7304\n",
      "Epoch 758/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.5581 - acc: 0.7281 - val_loss: 0.5494 - val_acc: 0.7217\n",
      "Epoch 759/1000\n",
      "537/537 [==============================] - 0s 75us/step - loss: 0.5572 - acc: 0.7169 - val_loss: 0.5507 - val_acc: 0.7304\n",
      "Epoch 760/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.5622 - acc: 0.7039 - val_loss: 0.5533 - val_acc: 0.7130\n",
      "Epoch 761/1000\n",
      "537/537 [==============================] - 0s 82us/step - loss: 0.5621 - acc: 0.7318 - val_loss: 0.5526 - val_acc: 0.7217\n",
      "Epoch 762/1000\n",
      "537/537 [==============================] - 0s 81us/step - loss: 0.5382 - acc: 0.7430 - val_loss: 0.5541 - val_acc: 0.7304\n",
      "Epoch 763/1000\n",
      "537/537 [==============================] - 0s 77us/step - loss: 0.5850 - acc: 0.6927 - val_loss: 0.5567 - val_acc: 0.7217\n",
      "Epoch 764/1000\n",
      "537/537 [==============================] - 0s 77us/step - loss: 0.6025 - acc: 0.6927 - val_loss: 0.5625 - val_acc: 0.7217\n",
      "Epoch 765/1000\n",
      "537/537 [==============================] - 0s 76us/step - loss: 0.5654 - acc: 0.7058 - val_loss: 0.5616 - val_acc: 0.7217\n",
      "Epoch 766/1000\n",
      "537/537 [==============================] - 0s 83us/step - loss: 0.5538 - acc: 0.7281 - val_loss: 0.5507 - val_acc: 0.7130\n",
      "Epoch 767/1000\n",
      "537/537 [==============================] - 0s 87us/step - loss: 0.5432 - acc: 0.7188 - val_loss: 0.5416 - val_acc: 0.7304\n",
      "Epoch 768/1000\n",
      "537/537 [==============================] - 0s 82us/step - loss: 0.5699 - acc: 0.6965 - val_loss: 0.5440 - val_acc: 0.7304\n",
      "Epoch 769/1000\n",
      "537/537 [==============================] - 0s 84us/step - loss: 0.5436 - acc: 0.7318 - val_loss: 0.5392 - val_acc: 0.7391\n",
      "Epoch 770/1000\n",
      "537/537 [==============================] - 0s 98us/step - loss: 0.5701 - acc: 0.7188 - val_loss: 0.5394 - val_acc: 0.7391\n",
      "Epoch 771/1000\n",
      "537/537 [==============================] - 0s 80us/step - loss: 0.5798 - acc: 0.7076 - val_loss: 0.5420 - val_acc: 0.7304\n",
      "Epoch 772/1000\n",
      "537/537 [==============================] - 0s 82us/step - loss: 0.5786 - acc: 0.7020 - val_loss: 0.5463 - val_acc: 0.7304\n",
      "Epoch 773/1000\n",
      "537/537 [==============================] - 0s 79us/step - loss: 0.5782 - acc: 0.6890 - val_loss: 0.5442 - val_acc: 0.7217\n",
      "Epoch 774/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.5648 - acc: 0.7132 - val_loss: 0.5405 - val_acc: 0.7304\n",
      "Epoch 775/1000\n",
      "537/537 [==============================] - 0s 79us/step - loss: 0.5344 - acc: 0.7207 - val_loss: 0.5347 - val_acc: 0.7217\n",
      "Epoch 776/1000\n",
      "537/537 [==============================] - 0s 73us/step - loss: 0.5893 - acc: 0.7244 - val_loss: 0.5421 - val_acc: 0.7217\n",
      "Epoch 777/1000\n",
      "537/537 [==============================] - 0s 77us/step - loss: 0.5380 - acc: 0.7393 - val_loss: 0.5387 - val_acc: 0.7391\n",
      "Epoch 778/1000\n",
      "537/537 [==============================] - 0s 76us/step - loss: 0.5747 - acc: 0.6965 - val_loss: 0.5449 - val_acc: 0.7391\n",
      "Epoch 779/1000\n",
      "537/537 [==============================] - 0s 85us/step - loss: 0.5918 - acc: 0.6983 - val_loss: 0.5499 - val_acc: 0.7217\n",
      "Epoch 780/1000\n",
      "537/537 [==============================] - 0s 81us/step - loss: 0.5437 - acc: 0.7225 - val_loss: 0.5471 - val_acc: 0.7217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 781/1000\n",
      "537/537 [==============================] - 0s 99us/step - loss: 0.5540 - acc: 0.7281 - val_loss: 0.5529 - val_acc: 0.7391\n",
      "Epoch 782/1000\n",
      "537/537 [==============================] - 0s 80us/step - loss: 0.5560 - acc: 0.7076 - val_loss: 0.5435 - val_acc: 0.7391\n",
      "Epoch 783/1000\n",
      "537/537 [==============================] - 0s 81us/step - loss: 0.5698 - acc: 0.7300 - val_loss: 0.5399 - val_acc: 0.7217\n",
      "Epoch 784/1000\n",
      "537/537 [==============================] - 0s 83us/step - loss: 0.5677 - acc: 0.7058 - val_loss: 0.5449 - val_acc: 0.7130\n",
      "Epoch 785/1000\n",
      "537/537 [==============================] - 0s 76us/step - loss: 0.5634 - acc: 0.7486 - val_loss: 0.5467 - val_acc: 0.7391\n",
      "Epoch 786/1000\n",
      "537/537 [==============================] - 0s 81us/step - loss: 0.5805 - acc: 0.7076 - val_loss: 0.5436 - val_acc: 0.7304\n",
      "Epoch 787/1000\n",
      "537/537 [==============================] - 0s 121us/step - loss: 0.5531 - acc: 0.7374 - val_loss: 0.5415 - val_acc: 0.7304\n",
      "Epoch 788/1000\n",
      "537/537 [==============================] - 0s 129us/step - loss: 0.5697 - acc: 0.7263 - val_loss: 0.5415 - val_acc: 0.7217\n",
      "Epoch 789/1000\n",
      "537/537 [==============================] - 0s 88us/step - loss: 0.5571 - acc: 0.7188 - val_loss: 0.5411 - val_acc: 0.7217\n",
      "Epoch 790/1000\n",
      "537/537 [==============================] - 0s 84us/step - loss: 0.5379 - acc: 0.7207 - val_loss: 0.5371 - val_acc: 0.7217\n",
      "Epoch 791/1000\n",
      "537/537 [==============================] - 0s 85us/step - loss: 0.5648 - acc: 0.7114 - val_loss: 0.5414 - val_acc: 0.7217\n",
      "Epoch 792/1000\n",
      "537/537 [==============================] - 0s 87us/step - loss: 0.5639 - acc: 0.7337 - val_loss: 0.5428 - val_acc: 0.7304\n",
      "Epoch 793/1000\n",
      "537/537 [==============================] - 0s 82us/step - loss: 0.5482 - acc: 0.7207 - val_loss: 0.5532 - val_acc: 0.7130\n",
      "Epoch 794/1000\n",
      "537/537 [==============================] - 0s 83us/step - loss: 0.5679 - acc: 0.7151 - val_loss: 0.5464 - val_acc: 0.7478\n",
      "Epoch 795/1000\n",
      "537/537 [==============================] - 0s 81us/step - loss: 0.5657 - acc: 0.7095 - val_loss: 0.5498 - val_acc: 0.7217\n",
      "Epoch 796/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.5703 - acc: 0.7076 - val_loss: 0.5450 - val_acc: 0.7217\n",
      "Epoch 797/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.5621 - acc: 0.7225 - val_loss: 0.5456 - val_acc: 0.7217\n",
      "Epoch 798/1000\n",
      "537/537 [==============================] - 0s 75us/step - loss: 0.5627 - acc: 0.7002 - val_loss: 0.5588 - val_acc: 0.7043\n",
      "Epoch 799/1000\n",
      "537/537 [==============================] - 0s 92us/step - loss: 0.5720 - acc: 0.6965 - val_loss: 0.5478 - val_acc: 0.7217\n",
      "Epoch 800/1000\n",
      "537/537 [==============================] - 0s 91us/step - loss: 0.5714 - acc: 0.7151 - val_loss: 0.5546 - val_acc: 0.7130\n",
      "Epoch 801/1000\n",
      "537/537 [==============================] - 0s 82us/step - loss: 0.5811 - acc: 0.7002 - val_loss: 0.5543 - val_acc: 0.7304\n",
      "Epoch 802/1000\n",
      "537/537 [==============================] - 0s 88us/step - loss: 0.5710 - acc: 0.7095 - val_loss: 0.5545 - val_acc: 0.7304\n",
      "Epoch 803/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.5647 - acc: 0.7188 - val_loss: 0.5520 - val_acc: 0.7217\n",
      "Epoch 804/1000\n",
      "537/537 [==============================] - 0s 100us/step - loss: 0.5626 - acc: 0.6965 - val_loss: 0.5614 - val_acc: 0.7043\n",
      "Epoch 805/1000\n",
      "537/537 [==============================] - 0s 83us/step - loss: 0.5600 - acc: 0.7151 - val_loss: 0.5551 - val_acc: 0.7391\n",
      "Epoch 806/1000\n",
      "537/537 [==============================] - 0s 76us/step - loss: 0.5651 - acc: 0.7151 - val_loss: 0.5660 - val_acc: 0.7217\n",
      "Epoch 807/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.5602 - acc: 0.7114 - val_loss: 0.5577 - val_acc: 0.7304\n",
      "Epoch 808/1000\n",
      "537/537 [==============================] - 0s 93us/step - loss: 0.5569 - acc: 0.7132 - val_loss: 0.5593 - val_acc: 0.7217\n",
      "Epoch 809/1000\n",
      "537/537 [==============================] - 0s 89us/step - loss: 0.5547 - acc: 0.7300 - val_loss: 0.5572 - val_acc: 0.7304\n",
      "Epoch 810/1000\n",
      "537/537 [==============================] - 0s 83us/step - loss: 0.5658 - acc: 0.7281 - val_loss: 0.5584 - val_acc: 0.7304\n",
      "Epoch 811/1000\n",
      "537/537 [==============================] - 0s 79us/step - loss: 0.5629 - acc: 0.6946 - val_loss: 0.5590 - val_acc: 0.7043\n",
      "Epoch 812/1000\n",
      "537/537 [==============================] - 0s 80us/step - loss: 0.5638 - acc: 0.7058 - val_loss: 0.5593 - val_acc: 0.7478\n",
      "Epoch 813/1000\n",
      "537/537 [==============================] - 0s 83us/step - loss: 0.5571 - acc: 0.7169 - val_loss: 0.5533 - val_acc: 0.7391\n",
      "Epoch 814/1000\n",
      "537/537 [==============================] - 0s 81us/step - loss: 0.5607 - acc: 0.7244 - val_loss: 0.5547 - val_acc: 0.7391\n",
      "Epoch 815/1000\n",
      "537/537 [==============================] - 0s 79us/step - loss: 0.5572 - acc: 0.7020 - val_loss: 0.5617 - val_acc: 0.7217\n",
      "Epoch 816/1000\n",
      "537/537 [==============================] - 0s 85us/step - loss: 0.5588 - acc: 0.7114 - val_loss: 0.5579 - val_acc: 0.7391\n",
      "Epoch 817/1000\n",
      "537/537 [==============================] - 0s 80us/step - loss: 0.5643 - acc: 0.7058 - val_loss: 0.5555 - val_acc: 0.7304\n",
      "Epoch 818/1000\n",
      "537/537 [==============================] - 0s 82us/step - loss: 0.5568 - acc: 0.7132 - val_loss: 0.5662 - val_acc: 0.7130\n",
      "Epoch 819/1000\n",
      "537/537 [==============================] - 0s 80us/step - loss: 0.5577 - acc: 0.7151 - val_loss: 0.5445 - val_acc: 0.7304\n",
      "Epoch 820/1000\n",
      "537/537 [==============================] - 0s 83us/step - loss: 0.5837 - acc: 0.7039 - val_loss: 0.5577 - val_acc: 0.7217\n",
      "Epoch 821/1000\n",
      "537/537 [==============================] - 0s 84us/step - loss: 0.5643 - acc: 0.7151 - val_loss: 0.5634 - val_acc: 0.7304\n",
      "Epoch 822/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.5464 - acc: 0.7430 - val_loss: 0.5620 - val_acc: 0.7304\n",
      "Epoch 823/1000\n",
      "537/537 [==============================] - 0s 81us/step - loss: 0.5707 - acc: 0.6927 - val_loss: 0.5645 - val_acc: 0.7130\n",
      "Epoch 824/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.5341 - acc: 0.7263 - val_loss: 0.5645 - val_acc: 0.7304\n",
      "Epoch 825/1000\n",
      "537/537 [==============================] - 0s 77us/step - loss: 0.5622 - acc: 0.7076 - val_loss: 0.5652 - val_acc: 0.7391\n",
      "Epoch 826/1000\n",
      "537/537 [==============================] - 0s 81us/step - loss: 0.5709 - acc: 0.7151 - val_loss: 0.5594 - val_acc: 0.7130\n",
      "Epoch 827/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.5443 - acc: 0.7412 - val_loss: 0.5644 - val_acc: 0.7304\n",
      "Epoch 828/1000\n",
      "537/537 [==============================] - 0s 84us/step - loss: 0.5555 - acc: 0.6965 - val_loss: 0.5648 - val_acc: 0.7217\n",
      "Epoch 829/1000\n",
      "537/537 [==============================] - 0s 75us/step - loss: 0.5658 - acc: 0.7188 - val_loss: 0.5616 - val_acc: 0.7217\n",
      "Epoch 830/1000\n",
      "537/537 [==============================] - 0s 113us/step - loss: 0.5533 - acc: 0.7281 - val_loss: 0.5598 - val_acc: 0.7478\n",
      "Epoch 831/1000\n",
      "537/537 [==============================] - 0s 84us/step - loss: 0.5551 - acc: 0.7132 - val_loss: 0.5586 - val_acc: 0.7217\n",
      "Epoch 832/1000\n",
      "537/537 [==============================] - 0s 81us/step - loss: 0.5645 - acc: 0.7281 - val_loss: 0.5672 - val_acc: 0.7304\n",
      "Epoch 833/1000\n",
      "537/537 [==============================] - 0s 80us/step - loss: 0.5553 - acc: 0.7393 - val_loss: 0.5609 - val_acc: 0.7304\n",
      "Epoch 834/1000\n",
      "537/537 [==============================] - 0s 80us/step - loss: 0.5818 - acc: 0.7002 - val_loss: 0.5647 - val_acc: 0.7130\n",
      "Epoch 835/1000\n",
      "537/537 [==============================] - 0s 80us/step - loss: 0.5811 - acc: 0.6946 - val_loss: 0.5678 - val_acc: 0.7217\n",
      "Epoch 836/1000\n",
      "537/537 [==============================] - 0s 81us/step - loss: 0.5551 - acc: 0.7151 - val_loss: 0.5653 - val_acc: 0.7391\n",
      "Epoch 837/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.5606 - acc: 0.7039 - val_loss: 0.5690 - val_acc: 0.7130\n",
      "Epoch 838/1000\n",
      "537/537 [==============================] - 0s 80us/step - loss: 0.5587 - acc: 0.7318 - val_loss: 0.5679 - val_acc: 0.7304\n",
      "Epoch 839/1000\n",
      "537/537 [==============================] - 0s 82us/step - loss: 0.5742 - acc: 0.6927 - val_loss: 0.5710 - val_acc: 0.7304\n",
      "Epoch 840/1000\n",
      "537/537 [==============================] - 0s 76us/step - loss: 0.5598 - acc: 0.7095 - val_loss: 0.5751 - val_acc: 0.7217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 841/1000\n",
      "537/537 [==============================] - 0s 76us/step - loss: 0.5710 - acc: 0.7188 - val_loss: 0.5731 - val_acc: 0.7304\n",
      "Epoch 842/1000\n",
      "537/537 [==============================] - 0s 79us/step - loss: 0.5743 - acc: 0.7076 - val_loss: 0.5793 - val_acc: 0.6957\n",
      "Epoch 843/1000\n",
      "537/537 [==============================] - 0s 80us/step - loss: 0.5622 - acc: 0.7300 - val_loss: 0.5760 - val_acc: 0.7304\n",
      "Epoch 844/1000\n",
      "537/537 [==============================] - 0s 79us/step - loss: 0.5656 - acc: 0.7263 - val_loss: 0.5790 - val_acc: 0.7217\n",
      "Epoch 845/1000\n",
      "537/537 [==============================] - 0s 77us/step - loss: 0.5842 - acc: 0.6965 - val_loss: 0.5752 - val_acc: 0.7304\n",
      "Epoch 846/1000\n",
      "537/537 [==============================] - 0s 76us/step - loss: 0.5638 - acc: 0.7076 - val_loss: 0.5748 - val_acc: 0.7130\n",
      "Epoch 847/1000\n",
      "537/537 [==============================] - 0s 76us/step - loss: 0.5723 - acc: 0.7300 - val_loss: 0.5769 - val_acc: 0.7217\n",
      "Epoch 848/1000\n",
      "537/537 [==============================] - 0s 79us/step - loss: 0.5773 - acc: 0.6983 - val_loss: 0.5784 - val_acc: 0.7217\n",
      "Epoch 849/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.5699 - acc: 0.7188 - val_loss: 0.5789 - val_acc: 0.7391\n",
      "Epoch 850/1000\n",
      "537/537 [==============================] - 0s 77us/step - loss: 0.5712 - acc: 0.7188 - val_loss: 0.5783 - val_acc: 0.7304\n",
      "Epoch 851/1000\n",
      "537/537 [==============================] - 0s 81us/step - loss: 0.5613 - acc: 0.7169 - val_loss: 0.5651 - val_acc: 0.7304\n",
      "Epoch 852/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.5541 - acc: 0.7318 - val_loss: 0.5789 - val_acc: 0.7304\n",
      "Epoch 853/1000\n",
      "537/537 [==============================] - 0s 79us/step - loss: 0.5778 - acc: 0.6965 - val_loss: 0.5706 - val_acc: 0.7217\n",
      "Epoch 854/1000\n",
      "537/537 [==============================] - 0s 75us/step - loss: 0.5477 - acc: 0.7318 - val_loss: 0.5765 - val_acc: 0.7304\n",
      "Epoch 855/1000\n",
      "537/537 [==============================] - 0s 85us/step - loss: 0.5795 - acc: 0.7169 - val_loss: 0.5807 - val_acc: 0.7304\n",
      "Epoch 856/1000\n",
      "537/537 [==============================] - 0s 77us/step - loss: 0.5605 - acc: 0.7151 - val_loss: 0.5765 - val_acc: 0.7130\n",
      "Epoch 857/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.5656 - acc: 0.7076 - val_loss: 0.5769 - val_acc: 0.7478\n",
      "Epoch 858/1000\n",
      "537/537 [==============================] - 0s 76us/step - loss: 0.5527 - acc: 0.7337 - val_loss: 0.5723 - val_acc: 0.7391\n",
      "Epoch 859/1000\n",
      "537/537 [==============================] - 0s 77us/step - loss: 0.5752 - acc: 0.7132 - val_loss: 0.5783 - val_acc: 0.7391\n",
      "Epoch 860/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.5728 - acc: 0.7132 - val_loss: 0.5840 - val_acc: 0.7304\n",
      "Epoch 861/1000\n",
      "537/537 [==============================] - 0s 77us/step - loss: 0.5612 - acc: 0.7151 - val_loss: 0.5849 - val_acc: 0.7478\n",
      "Epoch 862/1000\n",
      "537/537 [==============================] - 0s 76us/step - loss: 0.5691 - acc: 0.7076 - val_loss: 0.5821 - val_acc: 0.7217\n",
      "Epoch 863/1000\n",
      "537/537 [==============================] - 0s 82us/step - loss: 0.5482 - acc: 0.7300 - val_loss: 0.5831 - val_acc: 0.7304\n",
      "Epoch 864/1000\n",
      "537/537 [==============================] - 0s 77us/step - loss: 0.5609 - acc: 0.7058 - val_loss: 0.5857 - val_acc: 0.7391\n",
      "Epoch 865/1000\n",
      "537/537 [==============================] - 0s 82us/step - loss: 0.5578 - acc: 0.7318 - val_loss: 0.5825 - val_acc: 0.7478\n",
      "Epoch 866/1000\n",
      "537/537 [==============================] - 0s 92us/step - loss: 0.5476 - acc: 0.7114 - val_loss: 0.5761 - val_acc: 0.7304\n",
      "Epoch 867/1000\n",
      "537/537 [==============================] - 0s 87us/step - loss: 0.5911 - acc: 0.6983 - val_loss: 0.5868 - val_acc: 0.7130\n",
      "Epoch 868/1000\n",
      "537/537 [==============================] - 0s 82us/step - loss: 0.5558 - acc: 0.7169 - val_loss: 0.5784 - val_acc: 0.7304\n",
      "Epoch 869/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.5813 - acc: 0.6983 - val_loss: 0.5765 - val_acc: 0.7304\n",
      "Epoch 870/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.5620 - acc: 0.7188 - val_loss: 0.5772 - val_acc: 0.7217\n",
      "Epoch 871/1000\n",
      "537/537 [==============================] - 0s 84us/step - loss: 0.5852 - acc: 0.7002 - val_loss: 0.5857 - val_acc: 0.7043\n",
      "Epoch 872/1000\n",
      "537/537 [==============================] - 0s 79us/step - loss: 0.5794 - acc: 0.6965 - val_loss: 0.5776 - val_acc: 0.7217\n",
      "Epoch 873/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.5669 - acc: 0.7300 - val_loss: 0.5859 - val_acc: 0.7391\n",
      "Epoch 874/1000\n",
      "537/537 [==============================] - 0s 87us/step - loss: 0.5452 - acc: 0.7169 - val_loss: 0.5799 - val_acc: 0.7217\n",
      "Epoch 875/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.5745 - acc: 0.7095 - val_loss: 0.5813 - val_acc: 0.7304\n",
      "Epoch 876/1000\n",
      "537/537 [==============================] - 0s 82us/step - loss: 0.5476 - acc: 0.7337 - val_loss: 0.5814 - val_acc: 0.7130\n",
      "Epoch 877/1000\n",
      "537/537 [==============================] - 0s 82us/step - loss: 0.5646 - acc: 0.6965 - val_loss: 0.5853 - val_acc: 0.7304\n",
      "Epoch 878/1000\n",
      "537/537 [==============================] - 0s 86us/step - loss: 0.5603 - acc: 0.7263 - val_loss: 0.5848 - val_acc: 0.7304\n",
      "Epoch 879/1000\n",
      "537/537 [==============================] - 0s 76us/step - loss: 0.5573 - acc: 0.7374 - val_loss: 0.5874 - val_acc: 0.7217\n",
      "Epoch 880/1000\n",
      "537/537 [==============================] - 0s 75us/step - loss: 0.5498 - acc: 0.7374 - val_loss: 0.5885 - val_acc: 0.7304\n",
      "Epoch 881/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.5572 - acc: 0.7188 - val_loss: 0.5835 - val_acc: 0.7391\n",
      "Epoch 882/1000\n",
      "537/537 [==============================] - 0s 84us/step - loss: 0.5534 - acc: 0.7263 - val_loss: 0.5820 - val_acc: 0.7304\n",
      "Epoch 883/1000\n",
      "537/537 [==============================] - 0s 101us/step - loss: 0.5505 - acc: 0.7318 - val_loss: 0.5818 - val_acc: 0.7304\n",
      "Epoch 884/1000\n",
      "537/537 [==============================] - 0s 134us/step - loss: 0.5517 - acc: 0.7132 - val_loss: 0.5792 - val_acc: 0.7304\n",
      "Epoch 885/1000\n",
      "537/537 [==============================] - 0s 85us/step - loss: 0.5461 - acc: 0.7430 - val_loss: 0.5819 - val_acc: 0.7304\n",
      "Epoch 886/1000\n",
      "537/537 [==============================] - 0s 85us/step - loss: 0.5489 - acc: 0.7244 - val_loss: 0.5764 - val_acc: 0.7130\n",
      "Epoch 887/1000\n",
      "537/537 [==============================] - 0s 84us/step - loss: 0.5659 - acc: 0.7058 - val_loss: 0.5898 - val_acc: 0.7043\n",
      "Epoch 888/1000\n",
      "537/537 [==============================] - 0s 102us/step - loss: 0.5668 - acc: 0.7281 - val_loss: 0.5762 - val_acc: 0.7130\n",
      "Epoch 889/1000\n",
      "537/537 [==============================] - 0s 76us/step - loss: 0.5567 - acc: 0.7058 - val_loss: 0.5762 - val_acc: 0.7391\n",
      "Epoch 890/1000\n",
      "537/537 [==============================] - 0s 96us/step - loss: 0.5381 - acc: 0.7356 - val_loss: 0.5778 - val_acc: 0.7391\n",
      "Epoch 891/1000\n",
      "537/537 [==============================] - 0s 75us/step - loss: 0.5682 - acc: 0.7132 - val_loss: 0.5826 - val_acc: 0.7304\n",
      "Epoch 892/1000\n",
      "537/537 [==============================] - 0s 80us/step - loss: 0.5485 - acc: 0.7300 - val_loss: 0.5829 - val_acc: 0.7391\n",
      "Epoch 893/1000\n",
      "537/537 [==============================] - 0s 79us/step - loss: 0.5609 - acc: 0.7263 - val_loss: 0.5892 - val_acc: 0.7217\n",
      "Epoch 894/1000\n",
      "537/537 [==============================] - 0s 77us/step - loss: 0.5526 - acc: 0.7151 - val_loss: 0.5866 - val_acc: 0.7304\n",
      "Epoch 895/1000\n",
      "537/537 [==============================] - 0s 76us/step - loss: 0.5440 - acc: 0.7225 - val_loss: 0.5906 - val_acc: 0.7304\n",
      "Epoch 896/1000\n",
      "537/537 [==============================] - 0s 82us/step - loss: 0.5716 - acc: 0.7207 - val_loss: 0.5871 - val_acc: 0.7217\n",
      "Epoch 897/1000\n",
      "537/537 [==============================] - 0s 82us/step - loss: 0.5352 - acc: 0.7374 - val_loss: 0.5957 - val_acc: 0.7391\n",
      "Epoch 898/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.5525 - acc: 0.7263 - val_loss: 0.5884 - val_acc: 0.7478\n",
      "Epoch 899/1000\n",
      "537/537 [==============================] - 0s 84us/step - loss: 0.5429 - acc: 0.7244 - val_loss: 0.5816 - val_acc: 0.7217\n",
      "Epoch 900/1000\n",
      "537/537 [==============================] - 0s 77us/step - loss: 0.5426 - acc: 0.7244 - val_loss: 0.5849 - val_acc: 0.7217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 901/1000\n",
      "537/537 [==============================] - 0s 76us/step - loss: 0.5665 - acc: 0.7244 - val_loss: 0.5907 - val_acc: 0.7217\n",
      "Epoch 902/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.5649 - acc: 0.7132 - val_loss: 0.5933 - val_acc: 0.7130\n",
      "Epoch 903/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.5587 - acc: 0.7225 - val_loss: 0.5922 - val_acc: 0.7478\n",
      "Epoch 904/1000\n",
      "537/537 [==============================] - 0s 80us/step - loss: 0.5827 - acc: 0.6946 - val_loss: 0.5891 - val_acc: 0.7217\n",
      "Epoch 905/1000\n",
      "537/537 [==============================] - 0s 88us/step - loss: 0.5548 - acc: 0.7151 - val_loss: 0.5915 - val_acc: 0.7304\n",
      "Epoch 906/1000\n",
      "537/537 [==============================] - 0s 80us/step - loss: 0.5459 - acc: 0.7132 - val_loss: 0.5901 - val_acc: 0.7478\n",
      "Epoch 907/1000\n",
      "537/537 [==============================] - 0s 88us/step - loss: 0.5532 - acc: 0.7225 - val_loss: 0.5845 - val_acc: 0.7391\n",
      "Epoch 908/1000\n",
      "537/537 [==============================] - 0s 98us/step - loss: 0.5542 - acc: 0.7114 - val_loss: 0.5650 - val_acc: 0.7304\n",
      "Epoch 909/1000\n",
      "537/537 [==============================] - 0s 91us/step - loss: 0.5589 - acc: 0.7095 - val_loss: 0.5454 - val_acc: 0.7304\n",
      "Epoch 910/1000\n",
      "537/537 [==============================] - 0s 79us/step - loss: 0.5494 - acc: 0.7337 - val_loss: 0.5467 - val_acc: 0.7391\n",
      "Epoch 911/1000\n",
      "537/537 [==============================] - 0s 81us/step - loss: 0.5606 - acc: 0.7244 - val_loss: 0.5341 - val_acc: 0.7304\n",
      "Epoch 912/1000\n",
      "537/537 [==============================] - 0s 81us/step - loss: 0.5759 - acc: 0.7095 - val_loss: 0.5305 - val_acc: 0.7304\n",
      "Epoch 913/1000\n",
      "537/537 [==============================] - 0s 80us/step - loss: 0.5620 - acc: 0.7207 - val_loss: 0.5343 - val_acc: 0.7304\n",
      "Epoch 914/1000\n",
      "537/537 [==============================] - 0s 77us/step - loss: 0.5936 - acc: 0.6872 - val_loss: 0.5496 - val_acc: 0.7217\n",
      "Epoch 915/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.5658 - acc: 0.7095 - val_loss: 0.5433 - val_acc: 0.7217\n",
      "Epoch 916/1000\n",
      "537/537 [==============================] - 0s 75us/step - loss: 0.5316 - acc: 0.7207 - val_loss: 0.5478 - val_acc: 0.7391\n",
      "Epoch 917/1000\n",
      "537/537 [==============================] - 0s 81us/step - loss: 0.5727 - acc: 0.7076 - val_loss: 0.5523 - val_acc: 0.7217\n",
      "Epoch 918/1000\n",
      "537/537 [==============================] - 0s 79us/step - loss: 0.5571 - acc: 0.7281 - val_loss: 0.5555 - val_acc: 0.7130\n",
      "Epoch 919/1000\n",
      "537/537 [==============================] - 0s 80us/step - loss: 0.5604 - acc: 0.7169 - val_loss: 0.5469 - val_acc: 0.7304\n",
      "Epoch 920/1000\n",
      "537/537 [==============================] - 0s 79us/step - loss: 0.5325 - acc: 0.7598 - val_loss: 0.5473 - val_acc: 0.7217\n",
      "Epoch 921/1000\n",
      "537/537 [==============================] - 0s 82us/step - loss: 0.5611 - acc: 0.7244 - val_loss: 0.5474 - val_acc: 0.7391\n",
      "Epoch 922/1000\n",
      "537/537 [==============================] - 0s 77us/step - loss: 0.5910 - acc: 0.7225 - val_loss: 0.5617 - val_acc: 0.7304\n",
      "Epoch 923/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.5604 - acc: 0.7188 - val_loss: 0.5605 - val_acc: 0.6957\n",
      "Epoch 924/1000\n",
      "537/537 [==============================] - 0s 79us/step - loss: 0.5470 - acc: 0.7169 - val_loss: 0.5524 - val_acc: 0.7217\n",
      "Epoch 925/1000\n",
      "537/537 [==============================] - 0s 80us/step - loss: 0.5760 - acc: 0.7095 - val_loss: 0.5607 - val_acc: 0.7130\n",
      "Epoch 926/1000\n",
      "537/537 [==============================] - 0s 82us/step - loss: 0.5747 - acc: 0.7244 - val_loss: 0.5550 - val_acc: 0.7130\n",
      "Epoch 927/1000\n",
      "537/537 [==============================] - 0s 80us/step - loss: 0.5532 - acc: 0.7225 - val_loss: 0.5575 - val_acc: 0.7391\n",
      "Epoch 928/1000\n",
      "537/537 [==============================] - 0s 81us/step - loss: 0.5621 - acc: 0.7002 - val_loss: 0.5591 - val_acc: 0.7130\n",
      "Epoch 929/1000\n",
      "537/537 [==============================] - 0s 79us/step - loss: 0.5681 - acc: 0.7058 - val_loss: 0.5580 - val_acc: 0.7478\n",
      "Epoch 930/1000\n",
      "537/537 [==============================] - 0s 83us/step - loss: 0.5485 - acc: 0.7151 - val_loss: 0.5607 - val_acc: 0.7478\n",
      "Epoch 931/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.5523 - acc: 0.7058 - val_loss: 0.5722 - val_acc: 0.7304\n",
      "Epoch 932/1000\n",
      "537/537 [==============================] - 0s 80us/step - loss: 0.5806 - acc: 0.7151 - val_loss: 0.5677 - val_acc: 0.7391\n",
      "Epoch 933/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.5572 - acc: 0.7263 - val_loss: 0.5648 - val_acc: 0.7304\n",
      "Epoch 934/1000\n",
      "537/537 [==============================] - 0s 81us/step - loss: 0.5657 - acc: 0.7114 - val_loss: 0.5700 - val_acc: 0.7391\n",
      "Epoch 935/1000\n",
      "537/537 [==============================] - 0s 82us/step - loss: 0.5475 - acc: 0.7132 - val_loss: 0.5710 - val_acc: 0.7217\n",
      "Epoch 936/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.5530 - acc: 0.7318 - val_loss: 0.5630 - val_acc: 0.7304\n",
      "Epoch 937/1000\n",
      "537/537 [==============================] - 0s 79us/step - loss: 0.5628 - acc: 0.7151 - val_loss: 0.5689 - val_acc: 0.7478\n",
      "Epoch 938/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.5639 - acc: 0.7002 - val_loss: 0.5645 - val_acc: 0.7217\n",
      "Epoch 939/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.5410 - acc: 0.7244 - val_loss: 0.5688 - val_acc: 0.7478\n",
      "Epoch 940/1000\n",
      "537/537 [==============================] - 0s 75us/step - loss: 0.5614 - acc: 0.7169 - val_loss: 0.5699 - val_acc: 0.7391\n",
      "Epoch 941/1000\n",
      "537/537 [==============================] - 0s 79us/step - loss: 0.5703 - acc: 0.7114 - val_loss: 0.5667 - val_acc: 0.7391\n",
      "Epoch 942/1000\n",
      "537/537 [==============================] - 0s 79us/step - loss: 0.5749 - acc: 0.7169 - val_loss: 0.5726 - val_acc: 0.7304\n",
      "Epoch 943/1000\n",
      "537/537 [==============================] - 0s 76us/step - loss: 0.5579 - acc: 0.7225 - val_loss: 0.5716 - val_acc: 0.7391\n",
      "Epoch 944/1000\n",
      "537/537 [==============================] - 0s 77us/step - loss: 0.5447 - acc: 0.7225 - val_loss: 0.5772 - val_acc: 0.7304\n",
      "Epoch 945/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.5554 - acc: 0.7430 - val_loss: 0.5769 - val_acc: 0.7391\n",
      "Epoch 946/1000\n",
      "537/537 [==============================] - 0s 81us/step - loss: 0.5395 - acc: 0.7356 - val_loss: 0.5794 - val_acc: 0.7391\n",
      "Epoch 947/1000\n",
      "537/537 [==============================] - 0s 76us/step - loss: 0.5638 - acc: 0.7244 - val_loss: 0.5882 - val_acc: 0.7391\n",
      "Epoch 948/1000\n",
      "537/537 [==============================] - 0s 87us/step - loss: 0.5444 - acc: 0.7374 - val_loss: 0.5909 - val_acc: 0.7391\n",
      "Epoch 949/1000\n",
      "537/537 [==============================] - 0s 82us/step - loss: 0.5659 - acc: 0.7114 - val_loss: 0.5902 - val_acc: 0.7130\n",
      "Epoch 950/1000\n",
      "537/537 [==============================] - 0s 84us/step - loss: 0.5443 - acc: 0.7151 - val_loss: 0.5847 - val_acc: 0.7565\n",
      "Epoch 951/1000\n",
      "537/537 [==============================] - 0s 80us/step - loss: 0.5511 - acc: 0.7225 - val_loss: 0.5892 - val_acc: 0.7304\n",
      "Epoch 952/1000\n",
      "537/537 [==============================] - 0s 77us/step - loss: 0.5500 - acc: 0.7095 - val_loss: 0.5883 - val_acc: 0.7304\n",
      "Epoch 953/1000\n",
      "537/537 [==============================] - 0s 81us/step - loss: 0.5508 - acc: 0.7151 - val_loss: 0.5894 - val_acc: 0.7217\n",
      "Epoch 954/1000\n",
      "537/537 [==============================] - 0s 76us/step - loss: 0.5565 - acc: 0.7151 - val_loss: 0.5842 - val_acc: 0.7043\n",
      "Epoch 955/1000\n",
      "537/537 [==============================] - 0s 81us/step - loss: 0.5555 - acc: 0.7281 - val_loss: 0.5825 - val_acc: 0.7304\n",
      "Epoch 956/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.5686 - acc: 0.7188 - val_loss: 0.5886 - val_acc: 0.7217\n",
      "Epoch 957/1000\n",
      "537/537 [==============================] - 0s 75us/step - loss: 0.5590 - acc: 0.7114 - val_loss: 0.5841 - val_acc: 0.7304\n",
      "Epoch 958/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.5730 - acc: 0.7095 - val_loss: 0.5854 - val_acc: 0.7391\n",
      "Epoch 959/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.5665 - acc: 0.7095 - val_loss: 0.5848 - val_acc: 0.7043\n",
      "Epoch 960/1000\n",
      "537/537 [==============================] - 0s 82us/step - loss: 0.5619 - acc: 0.7244 - val_loss: 0.5820 - val_acc: 0.7478\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 961/1000\n",
      "537/537 [==============================] - 0s 86us/step - loss: 0.5430 - acc: 0.7207 - val_loss: 0.5821 - val_acc: 0.7217\n",
      "Epoch 962/1000\n",
      "537/537 [==============================] - 0s 76us/step - loss: 0.5680 - acc: 0.7169 - val_loss: 0.5831 - val_acc: 0.7304\n",
      "Epoch 963/1000\n",
      "537/537 [==============================] - 0s 75us/step - loss: 0.5583 - acc: 0.7188 - val_loss: 0.5850 - val_acc: 0.7304\n",
      "Epoch 964/1000\n",
      "537/537 [==============================] - 0s 75us/step - loss: 0.5414 - acc: 0.7412 - val_loss: 0.5850 - val_acc: 0.7217\n",
      "Epoch 965/1000\n",
      "537/537 [==============================] - 0s 85us/step - loss: 0.5629 - acc: 0.7281 - val_loss: 0.5789 - val_acc: 0.7391\n",
      "Epoch 966/1000\n",
      "537/537 [==============================] - 0s 80us/step - loss: 0.5625 - acc: 0.7263 - val_loss: 0.5751 - val_acc: 0.7391\n",
      "Epoch 967/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.5325 - acc: 0.7430 - val_loss: 0.5743 - val_acc: 0.7391\n",
      "Epoch 968/1000\n",
      "537/537 [==============================] - 0s 98us/step - loss: 0.5497 - acc: 0.7207 - val_loss: 0.5883 - val_acc: 0.7217\n",
      "Epoch 969/1000\n",
      "537/537 [==============================] - 0s 93us/step - loss: 0.5496 - acc: 0.7169 - val_loss: 0.5805 - val_acc: 0.7565\n",
      "Epoch 970/1000\n",
      "537/537 [==============================] - 0s 81us/step - loss: 0.5445 - acc: 0.7263 - val_loss: 0.5777 - val_acc: 0.7391\n",
      "Epoch 971/1000\n",
      "537/537 [==============================] - 0s 80us/step - loss: 0.5524 - acc: 0.7151 - val_loss: 0.5768 - val_acc: 0.7478\n",
      "Epoch 972/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.5393 - acc: 0.7207 - val_loss: 0.5766 - val_acc: 0.7565\n",
      "Epoch 973/1000\n",
      "537/537 [==============================] - 0s 76us/step - loss: 0.5723 - acc: 0.7132 - val_loss: 0.5726 - val_acc: 0.7304\n",
      "Epoch 974/1000\n",
      "537/537 [==============================] - 0s 76us/step - loss: 0.5421 - acc: 0.7356 - val_loss: 0.5813 - val_acc: 0.7478\n",
      "Epoch 975/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.5698 - acc: 0.7114 - val_loss: 0.5843 - val_acc: 0.7304\n",
      "Epoch 976/1000\n",
      "537/537 [==============================] - 0s 81us/step - loss: 0.5579 - acc: 0.7095 - val_loss: 0.5786 - val_acc: 0.7478\n",
      "Epoch 977/1000\n",
      "537/537 [==============================] - 0s 85us/step - loss: 0.5835 - acc: 0.7114 - val_loss: 0.5810 - val_acc: 0.7304\n",
      "Epoch 978/1000\n",
      "537/537 [==============================] - 0s 79us/step - loss: 0.5606 - acc: 0.7039 - val_loss: 0.5807 - val_acc: 0.7304\n",
      "Epoch 979/1000\n",
      "537/537 [==============================] - 0s 81us/step - loss: 0.5573 - acc: 0.7281 - val_loss: 0.5795 - val_acc: 0.7565\n",
      "Epoch 980/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.5633 - acc: 0.7188 - val_loss: 0.5722 - val_acc: 0.7391\n",
      "Epoch 981/1000\n",
      "537/537 [==============================] - 0s 76us/step - loss: 0.5600 - acc: 0.7244 - val_loss: 0.5746 - val_acc: 0.7391\n",
      "Epoch 982/1000\n",
      "537/537 [==============================] - 0s 75us/step - loss: 0.5482 - acc: 0.7318 - val_loss: 0.5716 - val_acc: 0.7304\n",
      "Epoch 983/1000\n",
      "537/537 [==============================] - 0s 76us/step - loss: 0.5536 - acc: 0.7281 - val_loss: 0.5753 - val_acc: 0.7304\n",
      "Epoch 984/1000\n",
      "537/537 [==============================] - 0s 82us/step - loss: 0.5531 - acc: 0.7151 - val_loss: 0.5756 - val_acc: 0.7391\n",
      "Epoch 985/1000\n",
      "537/537 [==============================] - 0s 75us/step - loss: 0.5497 - acc: 0.7207 - val_loss: 0.5754 - val_acc: 0.7304\n",
      "Epoch 986/1000\n",
      "537/537 [==============================] - 0s 81us/step - loss: 0.5594 - acc: 0.7188 - val_loss: 0.5811 - val_acc: 0.7478\n",
      "Epoch 987/1000\n",
      "537/537 [==============================] - 0s 84us/step - loss: 0.5538 - acc: 0.7188 - val_loss: 0.5769 - val_acc: 0.7652\n",
      "Epoch 988/1000\n",
      "537/537 [==============================] - 0s 89us/step - loss: 0.5670 - acc: 0.7244 - val_loss: 0.5782 - val_acc: 0.7478\n",
      "Epoch 989/1000\n",
      "537/537 [==============================] - 0s 81us/step - loss: 0.5496 - acc: 0.7244 - val_loss: 0.5777 - val_acc: 0.7391\n",
      "Epoch 990/1000\n",
      "537/537 [==============================] - 0s 77us/step - loss: 0.5788 - acc: 0.6946 - val_loss: 0.5786 - val_acc: 0.7391\n",
      "Epoch 991/1000\n",
      "537/537 [==============================] - 0s 94us/step - loss: 0.5357 - acc: 0.7430 - val_loss: 0.5725 - val_acc: 0.7478\n",
      "Epoch 992/1000\n",
      "537/537 [==============================] - 0s 83us/step - loss: 0.5805 - acc: 0.7188 - val_loss: 0.5777 - val_acc: 0.7565\n",
      "Epoch 993/1000\n",
      "537/537 [==============================] - 0s 83us/step - loss: 0.5653 - acc: 0.7151 - val_loss: 0.5849 - val_acc: 0.7391\n",
      "Epoch 994/1000\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.5501 - acc: 0.7300 - val_loss: 0.5798 - val_acc: 0.7478\n",
      "Epoch 995/1000\n",
      "537/537 [==============================] - 0s 80us/step - loss: 0.5542 - acc: 0.7132 - val_loss: 0.5804 - val_acc: 0.7391\n",
      "Epoch 996/1000\n",
      "537/537 [==============================] - 0s 83us/step - loss: 0.5570 - acc: 0.7114 - val_loss: 0.5793 - val_acc: 0.7304\n",
      "Epoch 997/1000\n",
      "537/537 [==============================] - 0s 89us/step - loss: 0.5581 - acc: 0.7169 - val_loss: 0.5788 - val_acc: 0.7478\n",
      "Epoch 998/1000\n",
      "537/537 [==============================] - 0s 91us/step - loss: 0.5624 - acc: 0.7207 - val_loss: 0.5805 - val_acc: 0.7304\n",
      "Epoch 999/1000\n",
      "537/537 [==============================] - 0s 97us/step - loss: 0.5566 - acc: 0.7169 - val_loss: 0.5870 - val_acc: 0.7391\n",
      "Epoch 1000/1000\n",
      "537/537 [==============================] - 0s 91us/step - loss: 0.5356 - acc: 0.7449 - val_loss: 0.5801 - val_acc: 0.7391\n"
     ]
    }
   ],
   "source": [
    "# 8. 학습시키기\n",
    "\n",
    "batch_size = 16\n",
    "epochs = 1000\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "         epochs=epochs,\n",
    "         batch_size=batch_size,\n",
    "         validation_data=(X_val, y_val), \n",
    "         verbose=1,\n",
    "         shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "537/537 [==============================] - 0s 21us/step\n",
      "116/116 [==============================] - 0s 27us/step\n",
      "Train Acc: [0.5100221896970738, 0.7541899434681045]\n",
      "Test Acc: [0.725729592915239, 0.6724137972141134]\n"
     ]
    }
   ],
   "source": [
    "# 9. 모델 평가하기\n",
    "train_accuracy = model.evaluate(X_train, y_train)\n",
    "test_accuracy = model.evaluate(X_test, y_test)\n",
    "\n",
    "print(\"Train Acc:\", train_accuracy)\n",
    "print(\"Test Acc:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 10. 학습 시각화하기\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Accuracy')\n",
    "plt.ylabel('epoch')\n",
    "plt.xlabel('accuracy')\n",
    "plt.legend(['train','test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Loss')\n",
    "plt.ylabel('epoch')\n",
    "plt.xlabel('loss')\n",
    "plt.legend(['train','test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 저장하기/불러오기\n",
    "model.save('my_model.h5') \n",
    "\n",
    "from keras.models import load_model\n",
    "model = load_model('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
